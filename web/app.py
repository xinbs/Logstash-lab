from flask import Flask, request, render_template, jsonify
import os, time, json, pathlib, re, subprocess
import urllib.request

app = Flask(__name__)
PIPELINE_PATH = "/app/pipeline/test.conf"
RESULT_FILE = "/app/data/out/events.ndjson"
LOGSTASH_HTTP = os.getenv("LOGSTASH_HTTP", "http://logstash:15515")

FILTER_PATTERN = re.compile(r"(filter\s*\{)(.*?)(\}\s*output\s*\{)", re.S)

DEFAULT_FILTER = """filter {
  grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }
  date { match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"] target => "@timestamp" }
}
"""

def extract_metadata_type_from_filter(filter_content):
    """ä» filter å†…å®¹ä¸­æå– metadata type"""
    # åŒ¹é… if "xxx" == [@metadata][type] { æ¨¡å¼
    match = re.search(r'if\s+"([^"]+)"\s*==\s*\[@metadata\]\[type\]', filter_content)
    return match.group(1) if match else ""

def wrap_filter_with_condition(filter_rules, metadata_type):
    """å°† filter è§„åˆ™åŒ…è£…åœ¨æ¡ä»¶åˆ¤æ–­ä¸­"""
    if not metadata_type.strip():
        return filter_rules
    
    # ç§»é™¤å¤–å±‚çš„ filter {} åŒ…è£…ï¼ˆå¦‚æœæœ‰ï¼‰
    content = filter_rules.strip()
    if content.startswith('filter'):
        # æå– filter { ... } ä¸­é—´çš„å†…å®¹
        match = re.match(r'filter\s*\{(.*)\}', content, re.DOTALL)
        if match:
            content = match.group(1).strip()
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰æ¡ä»¶åˆ¤æ–­ï¼Œå¦‚æœæœ‰åˆ™æå–å†…éƒ¨å†…å®¹
    # åŒ¹é… if "ä»»ä½•å€¼" == [@metadata][type] { ... } æ¨¡å¼
    condition_match = re.match(r'\s*if\s+"[^"]*"\s*==\s*\[@metadata\]\[type\]\s*\{(.*)\}\s*$', content, re.DOTALL)
    if condition_match:
        # å¦‚æœå·²ç»æœ‰æ¡ä»¶åˆ¤æ–­ï¼Œæå–å†…éƒ¨å†…å®¹
        content = condition_match.group(1).strip()
    
    # ç¼©è¿›å¤„ç†ï¼šä¸ºæ¯è¡Œæ·»åŠ é€‚å½“çš„ç¼©è¿›
    lines = content.split('\n')
    indented_lines = []
    for line in lines:
        if line.strip():  # åªå¯¹éç©ºè¡Œæ·»åŠ ç¼©è¿›
            indented_lines.append('        ' + line.lstrip())  # 8ä¸ªç©ºæ ¼ç¼©è¿›
        else:
            indented_lines.append('')
    
    indented_content = '\n'.join(indented_lines)
    
    # ç”Ÿæˆå¸¦æ¡ä»¶çš„ filterï¼Œå›ºå®šä½¿ç”¨ "test"
    wrapped = f'''filter {{
    if "test" == [@metadata][type] {{
{indented_content}
    }}
}}'''
    return wrapped

def write_filter(new_filter_block: str, metadata_type: str = ""):
    """æ›´æ–° pipeline é…ç½®æ–‡ä»¶ä¸­çš„ filter æ®µ"""
    with open(PIPELINE_PATH, "r", encoding="utf-8") as f:
        conf = f.read()
    
    lines = conf.split('\n')
    
    # å›ºå®šä½¿ç”¨ "test" ä½œä¸º metadata typeï¼Œæ›´æ–°ç¬¬ä¸€ä¸ª filter å—ä¸­çš„ metadata è®¾ç½®
    if metadata_type.strip():
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª filter å—ï¼ˆmetadata è®¾ç½®å—ï¼‰
        first_filter_updated = False
        for i, line in enumerate(lines):
            if 'add_field => { "[@metadata][type]"' in line:
                # å›ºå®šè®¾ç½®ä¸º "test"
                lines[i] = '    add_field => { "[@metadata][type]" => "test" }'
                first_filter_updated = True
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° metadata è®¾ç½®ï¼Œåœ¨ input åæ·»åŠ 
        if not first_filter_updated:
            input_end = -1
            for i, line in enumerate(lines):
                if line.strip() == '}' and i > 0:
                    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰ input ç›¸å…³å†…å®¹
                    prev_lines = '\n'.join(lines[max(0, i-10):i])
                    if 'input {' in prev_lines and 'http {' in prev_lines:
                        input_end = i
                        break
            
            if input_end != -1:
                metadata_filter = [
                    "",
                    "# è‡ªåŠ¨è®¾ç½® metadata typeï¼Œè¿™é‡Œä¼šè¢« Web ç•Œé¢åŠ¨æ€æ›¿æ¢",
                    "filter {",
                    "  mutate {",
                    f'    add_field => {{ "[@metadata][type]" => "{metadata_type}" }}',
                    "  }",
                    "}"
                ]
                lines = lines[:input_end + 1] + metadata_filter + lines[input_end + 1:]
    
    # æŸ¥æ‰¾ä¸»è¦çš„ filter å—ï¼ˆå¸¦æ³¨é‡Šæ ‡è®°çš„ï¼‰
    filter_start_line = -1
    filter_end_line = -1
    
    # æŸ¥æ‰¾å¸¦æœ‰æ›¿æ¢æ ‡è®°çš„ filter å—
    for i, line in enumerate(lines):
        if '!!! Web ä¼šæŠŠä¸‹é¢ filter' in line:
            # æ‰¾åˆ°ä¸‹ä¸€ä¸ª filter å—
            for j in range(i + 1, len(lines)):
                stripped = lines[j].strip()
                if stripped.startswith('filter {') or stripped == 'filter{':
                    filter_start_line = j
                    break
            break
    
    if filter_start_line == -1:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡è®°çš„ filter å—ï¼ŒæŸ¥æ‰¾æœ€åä¸€ä¸ª filter å—
        for i, line in enumerate(lines):
            stripped = line.strip()
            if stripped.startswith('#') or not stripped:
                continue
            if stripped.startswith('filter {') or stripped == 'filter{':
                filter_start_line = i
    
    if filter_start_line != -1:
        # æ‰¾åˆ° filter å—çš„ç»“æŸè¡Œ - æ”¹è¿›çš„ bracket counting
        bracket_count = 0
        in_string = False
        escape_next = False
        
        for i in range(filter_start_line, len(lines)):
            line = lines[i]
            for char in line:
                if escape_next:
                    escape_next = False
                    continue
                    
                if char == '\\':
                    escape_next = True
                    continue
                    
                if char == '"' and not escape_next:
                    in_string = not in_string
                    continue
                    
                if not in_string:
                    if char == '{':
                        bracket_count += 1
                    elif char == '}':
                        bracket_count -= 1
                        if bracket_count == 0:
                            filter_end_line = i
                            break
                            
            if filter_end_line != -1:
                break
        
        if filter_end_line == -1:
            # å¦‚æœæ— æ³•æ‰¾åˆ°ç»“æŸè¡Œï¼Œå°è¯•æŸ¥æ‰¾ä¸‹ä¸€ä¸ªé¡¶çº§å—ï¼ˆå¦‚ outputï¼‰
            for i in range(filter_start_line + 1, len(lines)):
                stripped = lines[i].strip()
                if stripped.startswith('output {') or stripped.startswith('input {'):
                    filter_end_line = i - 1
                    break
            
            if filter_end_line == -1:
                filter_end_line = len(lines) - 1
        
        # æ›¿æ¢ä¸»è¦çš„ filter å—
        new_lines = lines[:filter_start_line] + [new_filter_block] + lines[filter_end_line + 1:]
    else:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° filter å—ï¼Œåœ¨æœ€åæ·»åŠ 
        new_lines = lines + ["", new_filter_block]
    
    conf2 = '\n'.join(new_lines)
    
    with open(PIPELINE_PATH, "w", encoding="utf-8") as f:
        f.write(conf2)

def extract_current_filter(conf):
    """ä»å®Œæ•´é…ç½®ä¸­æå–å½“å‰çš„ filter å—"""
    lines = conf.split('\n')
    filter_start_line = -1
    filter_end_line = -1
    
    # æŸ¥æ‰¾ filter å—çš„å¼€å§‹è¡Œï¼ˆè·³è¿‡æ³¨é‡Šï¼‰
    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.startswith('#') or not stripped:
            continue
        if stripped.startswith('filter {') or stripped == 'filter{':
            filter_start_line = i
            break
    
    if filter_start_line == -1:
        return DEFAULT_FILTER
    
    # æ‰¾åˆ° filter å—çš„ç»“æŸè¡Œ
    bracket_count = 0
    for i in range(filter_start_line, len(lines)):
        line = lines[i]
        for char in line:
            if char == '{':
                bracket_count += 1
            elif char == '}':
                bracket_count -= 1
                if bracket_count == 0:
                    filter_end_line = i
                    break
        if filter_end_line != -1:
            break
    
    if filter_end_line == -1:
        return DEFAULT_FILTER
    
    return '\n'.join(lines[filter_start_line:filter_end_line + 1])

@app.route("/", methods=["GET"])
def index():
    """ä¸»é¡µé¢ - æ˜¾ç¤ºå½“å‰ filter é…ç½®å’Œæœ€è¿‘ç»“æœ"""
    # è¯»å–å½“å‰ filter
    with open(PIPELINE_PATH, "r", encoding="utf-8") as f:
        conf = f.read()
    current_filter = extract_current_filter(conf)
    
    # æå–å½“å‰çš„ metadata type
    current_metadata_type = extract_metadata_type_from_filter(current_filter)
    
    # è¯»å–æœ€è¿‘ 50 æ¡ç»“æœ
    last = []
    if os.path.exists(RESULT_FILE):
        with open(RESULT_FILE, "rb") as f:
            f.seek(0, os.SEEK_END)
            size = f.tell()
            f.seek(max(0, size-200000), os.SEEK_SET)  # é˜²çˆ†å†…å­˜
            lines = f.read().decode("utf-8", "ignore").splitlines()
            last = lines[-50:]
    
    return render_template("index.html", 
                         current_filter=current_filter, 
                         current_metadata_type=current_metadata_type,
                         last=last)

@app.route("/save_filter", methods=["POST"])
def save_filter():
    """ä¿å­˜ filter é…ç½®"""
    filter_data = request.form.get("filter", "")
    # å›ºå®šä½¿ç”¨ "test" ä½œä¸º metadata type
    metadata_type = "test"
    auto_wrap_condition = True  # é»˜è®¤æ€»æ˜¯è‡ªåŠ¨åŒ…è£…
    
    # å¤„ç† filter å†…å®¹
    if not filter_data.strip():
        filter_data = DEFAULT_FILTER
    
    # æ€»æ˜¯é€šè¿‡ wrap_filter_with_condition å¤„ç†ï¼Œä»¥ç¡®ä¿æ¡ä»¶åˆ¤æ–­ä½¿ç”¨æ­£ç¡®çš„å€¼
    block = wrap_filter_with_condition(filter_data, metadata_type)
    
    write_filter(block, metadata_type)
    
    # æ„é€ å“åº”æ¶ˆæ¯
    message = f"Filter å·²ä¿å­˜å¹¶è‡ªåŠ¨é‡è½½ (å·²è‡ªåŠ¨æ·»åŠ æ¡ä»¶åˆ¤æ–­: if \"test\" == [@metadata][type])"
    
    return jsonify({"ok": True, "message": message})

@app.route("/test", methods=["POST"])
def test_send():
    """å‘é€æµ‹è¯•æ—¥å¿—åˆ° Logstash"""
    body = request.form.get("logs", "")
    is_json = request.form.get("is_json") == "1"
    
    if not body.strip():
        return jsonify({"ok": False, "message": "è¯·è¾“å…¥æµ‹è¯•æ—¥å¿—å†…å®¹"})
    
    req = urllib.request.Request(
        LOGSTASH_HTTP,
        data=body.encode("utf-8"),
        headers={"Content-Type": "application/json" if is_json else "text/plain"},
        method="POST",
    )
    
    try:
        urllib.request.urlopen(req, timeout=3)
        send_status = "âœ… æ—¥å¿—å‘é€æˆåŠŸ"
    except Exception as e:
        send_status = f"âŒ æ—¥å¿—å‘é€å¤±è´¥: {e}"
    
    # ç®€å•ç­‰å¾… Logstash flush
    time.sleep(0.6)
    
    # å›è¯»æœ«å°¾ 50 æ¡
    out = []
    if os.path.exists(RESULT_FILE):
        with open(RESULT_FILE, "rb") as f:
            f.seek(0, os.SEEK_END)
            size = f.tell()
            f.seek(max(0, size-200000), os.SEEK_SET)
            lines = f.read().decode("utf-8", "ignore").splitlines()
            out = lines[-50:]
    
    events = []
    for line in out:
        if line.strip():
            try:
                events.append(json.loads(line))
            except:
                pass
    
    return jsonify({
        "ok": True, 
        "message": send_status,
        "events": events
    })

@app.route("/clear_results", methods=["POST"])
def clear_results():
    """æ¸…ç©ºç»“æœæ–‡ä»¶"""
    try:
        if os.path.exists(RESULT_FILE):
            open(RESULT_FILE, 'w').close()
        return jsonify({"ok": True, "message": "ç»“æœå·²æ¸…ç©º"})
    except Exception as e:
        return jsonify({"ok": False, "message": f"æ¸…ç©ºå¤±è´¥: {e}"})

@app.route("/get_parsed_results", methods=["GET"])
def get_parsed_results():
    """è·å–æœ€æ–°çš„è§£æè®°å½•"""
    try:
        events = []
        current_time = time.strftime("%Y-%m-%d %H:%M:%S")
        
        if os.path.exists(RESULT_FILE):
            with open(RESULT_FILE, "rb") as f:
                f.seek(0, os.SEEK_END)
                size = f.tell()
                f.seek(max(0, size-500000), os.SEEK_SET)  # è¯»å–æœ€å 500KB
                lines = f.read().decode("utf-8", "ignore").splitlines()
                
                # è·å–æœ€æ–°çš„ 50 æ¡è®°å½•
                recent_lines = lines[-50:] if len(lines) > 50 else lines
                
                for line in recent_lines:
                    if line.strip():
                        try:
                            event = json.loads(line)
                            # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯
                            if '@timestamp' in event:
                                event['_parsed_time'] = current_time
                            events.append(event)
                        except json.JSONDecodeError:
                            # è·³è¿‡æ— æ•ˆçš„ JSON è¡Œ
                            continue
        
        return jsonify({
            "ok": True, 
            "events": events,
            "count": len(events),
            "message": f"æˆåŠŸè·å– {len(events)} æ¡è§£æè®°å½•"
        })
        
    except Exception as e:
        return jsonify({"ok": False, "message": f"è·å–è§£æè®°å½•å¤±è´¥: {e}"})

@app.route("/logstash_logs", methods=["GET"])
def logstash_logs():
    """è·å– Logstash æ—¥å¿—"""
    try:
        logs_content = []
        current_time = time.strftime("%Y-%m-%d %H:%M:%S")
        
        # å®šä¹‰å¯èƒ½çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_paths = [
            "/app/data/../logs/logstash-plain.log",    # é€šè¿‡æŒ‚è½½è®¿é—®
            "/app/data/../logs/logstash.log",
            "/logs/logstash-plain.log",                # ç›´æ¥æ—¥å¿—æŒ‚è½½
            "/logs/logstash.log"
        ]
        
        # å°è¯•è¯»å–æ—¥å¿—æ–‡ä»¶
        log_file_found = False
        for log_path in log_paths:
            if os.path.exists(log_path):
                log_file_found = True
                try:
                    with open(log_path, 'r', encoding='utf-8', errors='ignore') as f:
                        # è¯»å–æœ€å 100 è¡Œ
                        lines = f.readlines()
                        recent_lines = lines[-100:] if len(lines) > 100 else lines
                        
                        logs_content.append(f"ğŸ“‹ Logstash æ—¥å¿—æ–‡ä»¶: {log_path}")
                        logs_content.append(f"ğŸ“… è¯»å–æ—¶é—´: {current_time}")
                        logs_content.append(f"ğŸ“Š æ˜¾ç¤ºæœ€è¿‘ {len(recent_lines)} æ¡æ—¥å¿—")
                        logs_content.append("=" * 80)
                        logs_content.extend([line.rstrip() for line in recent_lines])
                        break
                        
                except Exception as e:
                    logs_content.append(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
                    continue
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œå°è¯•é€šè¿‡ Docker API è·å–å®¹å™¨æ—¥å¿—
        if not log_file_found:
            try:
                import subprocess
                result = subprocess.run([
                    "docker", "logs", "--tail", "50", "logstash-lab"
                ], capture_output=True, text=True, timeout=10, cwd="/")
                
                if result.returncode == 0:
                    logs_content.append(f"ğŸ“‹ Logstash å®¹å™¨æ—¥å¿— (Docker API)")
                    logs_content.append(f"ğŸ“… è·å–æ—¶é—´: {current_time}")
                    logs_content.append("ğŸ“Š æ˜¾ç¤ºæœ€è¿‘ 50 æ¡æ—¥å¿—")
                    logs_content.append("=" * 80)
                    
                    # åˆå¹¶ stdout å’Œ stderr
                    container_logs = result.stdout + result.stderr
                    logs_content.extend(container_logs.splitlines())
                else:
                    raise Exception(f"Docker å‘½ä»¤æ‰§è¡Œå¤±è´¥: {result.stderr}")
                    
            except Exception as docker_error:
                # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›æŒ‡å¯¼ä¿¡æ¯
                logs_content = [
                    f"ğŸ“‹ Logstash æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½",
                    f"ğŸ“… å½“å‰æ—¶é—´: {current_time}",
                    "",
                    "âš ï¸ æš‚æ—¶æ— æ³•ç›´æ¥è¯»å–æ—¥å¿—æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¡Œæ–¹å¼ï¼š",
                    "",
                    "ğŸ”§ æŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼š",
                    "sudo docker compose logs -f logstash",
                    "",
                    "ğŸ“Š æŸ¥çœ‹æœ€è¿‘ 50 æ¡æ—¥å¿—ï¼š",
                    "sudo docker compose logs --tail=50 logstash",
                    "",
                    "ğŸ” æŸ¥çœ‹æœ€è¿‘ 100 æ¡æ—¥å¿—ï¼š",
                    "sudo docker compose logs --tail=100 logstash",
                    "",
                    "âš¡ åªçœ‹é”™è¯¯æ—¥å¿—ï¼š",
                    "sudo docker compose logs logstash | grep -i error",
                    "",
                    f"âŒ é”™è¯¯ä¿¡æ¯: {docker_error}",
                    "",
                    "ğŸ’¡ æç¤º: é‡å¯å®¹å™¨åæ—¥å¿—æ–‡ä»¶å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ç”Ÿæˆ"
                ]
        
        return jsonify({"ok": True, "logs": "\n".join(logs_content)})
        
    except Exception as e:
        return jsonify({"ok": False, "message": f"è·å–æ—¥å¿—å¤±è´¥: {e}"})

def extract_filter_from_pipeline(pipeline_content):
    """ä» pipeline é…ç½®ä¸­æå– filter å—å†…å®¹"""
    lines = pipeline_content.split('\n')
    filter_blocks = []
    current_block = []
    in_filter_block = False
    bracket_count = 0
    in_string = False
    escape_next = False
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
        if not stripped or stripped.startswith('#'):
            if in_filter_block:
                current_block.append(line)
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ filter å—çš„å¼€å§‹
        if stripped.startswith('filter') and '{' in stripped and not in_filter_block:
            in_filter_block = True
            current_block = [line]
            bracket_count = 0
            
            # è®¡ç®—è¿™ä¸€è¡Œçš„æ‹¬å·
            for char in stripped:
                if escape_next:
                    escape_next = False
                    continue
                if char == '\\':
                    escape_next = True
                    continue
                if char == '"' and not escape_next:
                    in_string = not in_string
                if not in_string:
                    if char == '{':
                        bracket_count += 1
                    elif char == '}':
                        bracket_count -= 1
            
            if bracket_count == 0:
                # å•è¡Œ filter å—
                filter_blocks.append('\n'.join(current_block))
                in_filter_block = False
                current_block = []
        elif in_filter_block:
            current_block.append(line)
            
            # è®¡ç®—è¿™ä¸€è¡Œçš„æ‹¬å·
            for char in line:
                if escape_next:
                    escape_next = False
                    continue
                if char == '\\':
                    escape_next = True
                    continue
                if char == '"' and not escape_next:
                    in_string = not in_string
                if not in_string:
                    if char == '{':
                        bracket_count += 1
                    elif char == '}':
                        bracket_count -= 1
            
            # æ£€æŸ¥æ˜¯å¦ç»“æŸ
            if bracket_count == 0:
                filter_blocks.append('\n'.join(current_block))
                in_filter_block = False
                current_block = []
    
    return filter_blocks

def extract_main_filter_content(filter_block):
    """ä» filter å—ä¸­æå–ä¸»è¦å†…å®¹ï¼ˆå»é™¤å¤–å±‚ filter {} åŒ…è£…ï¼‰"""
    lines = filter_block.split('\n')
    content_lines = []
    found_opening = False
    bracket_count = 0
    in_string = False
    escape_next = False
    
    for line in lines:
        stripped = line.strip()
        
        if not found_opening:
            if stripped.startswith('filter') and '{' in stripped:
                found_opening = True
                # æå– { åé¢çš„å†…å®¹
                brace_pos = line.find('{')
                after_brace = line[brace_pos + 1:].strip()
                if after_brace:
                    content_lines.append(after_brace)
                continue
            continue
        
        # è®¡ç®—æ‹¬å·å±‚çº§
        line_bracket_count = bracket_count
        for char in line:
            if escape_next:
                escape_next = False
                continue
            if char == '\\':
                escape_next = True
                continue
            if char == '"' and not escape_next:
                in_string = not in_string
            if not in_string:
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
        
        # å¦‚æœè¿™ä¸€è¡Œç»“æŸåæ‹¬å·å¹³è¡¡äº†ï¼Œè¯´æ˜è¿™æ˜¯æœ€åä¸€è¡Œ
        if bracket_count < 0:
            # å»é™¤æœ€åçš„ }
            brace_pos = line.rfind('}')
            if brace_pos >= 0:
                before_brace = line[:brace_pos].rstrip()
                if before_brace:
                    content_lines.append(before_brace)
            break
        else:
            content_lines.append(line)
    
    return '\n'.join(content_lines)

@app.route("/upload_pipeline", methods=["POST"])
def upload_pipeline():
    """æ¥æ”¶ pipeline é…ç½®æ–‡ä»¶ï¼Œæå– filter å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒ"""
    try:
        # è·å–ä¸Šä¼ çš„å†…å®¹
        if 'file' in request.files:
            # æ–‡ä»¶ä¸Šä¼ 
            file = request.files['file']
            if file.filename == '':
                return jsonify({"ok": False, "message": "æœªé€‰æ‹©æ–‡ä»¶"})
            pipeline_content = file.read().decode('utf-8')
        elif 'pipeline' in request.form:
            # è¡¨å•æ•°æ®
            pipeline_content = request.form.get('pipeline', '')
        else:
            return jsonify({"ok": False, "message": "æœªæä¾› pipeline å†…å®¹"})
        
        if not pipeline_content.strip():
            return jsonify({"ok": False, "message": "Pipeline å†…å®¹ä¸ºç©º"})
        
        # æå– filter å—
        filter_blocks = extract_filter_from_pipeline(pipeline_content)
        
        if not filter_blocks:
            return jsonify({"ok": False, "message": "æœªåœ¨ pipeline ä¸­æ‰¾åˆ° filter å—"})
        
        # é€‰æ‹©æœ€åä¸€ä¸ª filter å—ï¼ˆé€šå¸¸æ˜¯ä¸»è¦çš„å¤„ç†é€»è¾‘ï¼‰
        main_filter_block = filter_blocks[-1]
        
        # æå– filter å†…å®¹ï¼ˆå»é™¤å¤–å±‚åŒ…è£…ï¼‰
        filter_content = extract_main_filter_content(main_filter_block)
        
        if not filter_content.strip():
            return jsonify({"ok": False, "message": "æå–çš„ filter å†…å®¹ä¸ºç©º"})
        
        # åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒï¼ˆä½¿ç”¨ç°æœ‰çš„é€»è¾‘ï¼‰
        metadata_type = "test"
        
        # åŒ…è£… filter å†…å®¹
        block = wrap_filter_with_condition(filter_content, metadata_type)
        
        # å†™å…¥é…ç½®æ–‡ä»¶
        write_filter(block, metadata_type)
        
        return jsonify({
            "ok": True, 
            "message": f"Pipeline å·²æˆåŠŸä¸Šä¼ å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒ",
            "extracted_filters": len(filter_blocks),
            "applied_filter_preview": filter_content[:200] + "..." if len(filter_content) > 200 else filter_content
        })
        
    except Exception as e:
        return jsonify({"ok": False, "message": f"å¤„ç† pipeline å¤±è´¥: {str(e)}"})

if __name__ == "__main__":
    # åˆå§‹åŒ–ï¼šç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(PIPELINE_PATH), exist_ok=True)
    os.makedirs(os.path.dirname(RESULT_FILE), exist_ok=True)
    
    # å¼€å‘æ¨¡å¼ï¼šä½¿ç”¨ Flask å¼€å‘æœåŠ¡å™¨ï¼ˆæ”¯æŒè‡ªåŠ¨é‡è½½ï¼‰
    if os.getenv("FLASK_ENV") == "development":
        app.run(host="0.0.0.0", port=int(os.getenv("PORT", 19000)), debug=True)
    else:
        # ç”Ÿäº§æ¨¡å¼ï¼šä½¿ç”¨ Waitress
        from waitress import serve
        serve(app, host="0.0.0.0", port=int(os.getenv("PORT", 19000)))
