# ğŸ¤– AI é›†æˆè°ƒç”¨æŒ‡å—

**é¢å‘ç¬¬ä¸‰æ–¹ AI çš„ Logstash è§„åˆ™æµ‹è¯•æœåŠ¡è°ƒç”¨æ–‡æ¡£**

æœ¬æ–‡æ¡£ä¸“é—¨ä¸ºç¬¬ä¸‰æ–¹ AI ç³»ç»Ÿæä¾›å®Œæ•´çš„è°ƒç”¨æŒ‡å—ï¼Œå®ç°è‡ªåŠ¨åŒ–çš„ Logstash è§„åˆ™æµ‹è¯•å’ŒéªŒè¯ã€‚

---

## ğŸ“‹ æœåŠ¡æ¦‚è¿°

### ğŸ¯ **æœåŠ¡åŠŸèƒ½**
- **Logstash Filter è§„åˆ™ç¼–è¾‘å’ŒéªŒè¯**
- **å®æ—¶æ—¥å¿—è§£ææµ‹è¯•**
- **è§£æç»“æœè·å–å’Œåˆ†æ**
- **è°ƒè¯•æ—¥å¿—æŸ¥çœ‹**
- **è‡ªåŠ¨åŒ–æµ‹è¯•å·¥ä½œæµ**

### ğŸŒ **æœåŠ¡åœ°å€**
```
Base URL: http://localhost:19000
Health Check: GET /get_parsed_results
```

### ğŸ”‘ **æ ¸å¿ƒç‰¹æ€§**
- âœ… **æ— éœ€è®¤è¯**ï¼šç›´æ¥è°ƒç”¨ API
- âœ… **çƒ­é‡è½½**ï¼šé…ç½®ä¿®æ”¹ 3 ç§’å†…ç”Ÿæ•ˆ
- âœ… **æ™ºèƒ½å¤„ç†**ï¼šè‡ªåŠ¨æ¡ä»¶åˆ¤æ–­æ›¿æ¢
- âœ… **å®æ—¶åé¦ˆ**ï¼šå³æ—¶è·å–è§£æç»“æœ
- âœ… **é”™è¯¯å¤„ç†**ï¼šè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

---

## ğŸš€ AI è°ƒç”¨å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ **æœåŠ¡å¥åº·æ£€æŸ¥**

åœ¨å¼€å§‹è°ƒç”¨å‰ï¼Œå…ˆæ£€æŸ¥æœåŠ¡çŠ¶æ€ï¼š

```bash
# æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
curl -s http://localhost:19000/get_parsed_results > /dev/null
echo "Service status: $?"  # 0=å¯ç”¨, é0=ä¸å¯ç”¨
```

**AI å®ç°å»ºè®®**ï¼š
```python
import requests

def check_service_health():
    try:
        response = requests.get("http://localhost:19000/get_parsed_results", timeout=5)
        return response.status_code == 200
    except:
        return False
```

### 2ï¸âƒ£ **åŸºæœ¬è°ƒç”¨å·¥ä½œæµ**

```bash
#!/bin/bash
# AI è‡ªåŠ¨åŒ–æµ‹è¯•å·¥ä½œæµ

BASE_URL="http://localhost:19000"

# 1. æ¸…ç©ºå†å²æ•°æ®
curl -s -X POST "$BASE_URL/clear_results"

# 2. ä¿å­˜ Filter è§„åˆ™
curl -s -X POST "$BASE_URL/save_filter" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "filter=grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } }"

# 3. ç­‰å¾…çƒ­é‡è½½
sleep 3

# 4. å‘é€æµ‹è¯•æ—¥å¿—
curl -s -X POST "$BASE_URL/test" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "logs=127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326"

# 5. è·å–è§£æç»“æœ
curl -s "$BASE_URL/get_parsed_results" | jq .
```

---

## ğŸ”§ API æ¥å£è¯¦ç»†è¯´æ˜

### ğŸ› ï¸ **1. ä¿å­˜ Filter è§„åˆ™**

**ç«¯ç‚¹**: `POST /save_filter`

**åŠŸèƒ½**: ä¿å­˜ Logstash filter é…ç½®å¹¶è‡ªåŠ¨é‡è½½

**è¯·æ±‚æ ¼å¼**:
```http
POST /save_filter HTTP/1.1
Host: localhost:19000
Content-Type: application/x-www-form-urlencoded

filter=<FILTER_CONTENT>
```

**AI è°ƒç”¨ç¤ºä¾‹**:
```python
import requests
import urllib.parse

def save_filter(filter_content):
    url = "http://localhost:19000/save_filter"
    data = {"filter": filter_content}
    
    response = requests.post(
        url, 
        data=data,
        headers={"Content-Type": "application/x-www-form-urlencoded"}
    )
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
filter_rule = """
grok {
  match => { "message" => "%{COMBINEDAPACHELOG}" }
}
mutate {
  rename => { "clientip" => "src_ip" }
}
"""

result = save_filter(filter_rule)
print(f"ä¿å­˜ç»“æœ: {result['message']}")
```

**æ™ºèƒ½åŠŸèƒ½**:
- è‡ªåŠ¨å°†ä»»ä½• `if "xxx" == [@metadata][type]` æ›¿æ¢ä¸º `if "test" == [@metadata][type]`
- è‡ªåŠ¨è®¾ç½®å…ƒæ•°æ®ç±»å‹ä¸º "test"
- 3 ç§’å†…è‡ªåŠ¨çƒ­é‡è½½

**å“åº”æ ¼å¼**:
```json
{
  "ok": true,
  "message": "Filter å·²ä¿å­˜å¹¶è‡ªåŠ¨é‡è½½ (å·²è‡ªåŠ¨æ·»åŠ æ¡ä»¶åˆ¤æ–­: if \"test\" == [@metadata][type])"
}
```

### ğŸ“Š **2. å‘é€æµ‹è¯•æ—¥å¿—**

**ç«¯ç‚¹**: `POST /test`

**åŠŸèƒ½**: å‘é€æµ‹è¯•æ—¥å¿—åˆ° Logstash å¹¶è·å–è§£æç»“æœ

**è¯·æ±‚å‚æ•°**:
- `logs`: è¦æµ‹è¯•çš„æ—¥å¿—å†…å®¹ï¼ˆå¿…éœ€ï¼‰
- `is_json`: æ˜¯å¦ä¸º JSON æ ¼å¼ï¼Œå€¼ä¸º "1" è¡¨ç¤ºæ˜¯ï¼ˆå¯é€‰ï¼‰

**AI è°ƒç”¨ç¤ºä¾‹**:
```python
def send_test_log(log_content, is_json=False):
    url = "http://localhost:19000/test"
    data = {
        "logs": log_content
    }
    if is_json:
        data["is_json"] = "1"
    
    response = requests.post(url, data=data)
    return response.json()

# æµ‹è¯•çº¯æ–‡æœ¬æ—¥å¿—
apache_log = '127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326'
result = send_test_log(apache_log)
print(f"è§£æç»“æœ: {result['events']}")

# æµ‹è¯• JSON æ—¥å¿—
json_log = '{"timestamp": "2023-12-25T10:00:00Z", "level": "info", "message": "ç”¨æˆ·ç™»å½•æˆåŠŸ"}'
result = send_test_log(json_log, is_json=True)
```

**å“åº”æ ¼å¼**:
```json
{
  "ok": true,
  "message": "âœ… æ—¥å¿—å‘é€æˆåŠŸ",
  "events": [
    {
      "@timestamp": "2024-12-25T10:00:00.000Z",
      "message": "åŸå§‹æ—¥å¿—å†…å®¹",
      "clientip": "127.0.0.1",
      "verb": "GET",
      "request": "/index.html",
      "src_ip": "127.0.0.1"
    }
  ]
}
```

### ğŸ“ˆ **3. è·å–è§£æç»“æœ**

**ç«¯ç‚¹**: `GET /get_parsed_results`

**åŠŸèƒ½**: è·å–æœ€æ–°çš„è§£æè®°å½•ï¼ˆæœ€å¤š 50 æ¡ï¼‰

**AI è°ƒç”¨ç¤ºä¾‹**:
```python
def get_parsed_results():
    url = "http://localhost:19000/get_parsed_results"
    response = requests.get(url)
    return response.json()

def analyze_results():
    results = get_parsed_results()
    
    if results["ok"]:
        events = results["events"]
        count = results["count"]
        
        print(f"è·å–åˆ° {count} æ¡è§£æè®°å½•")
        
        # åˆ†æè§£æç»“æœ
        for i, event in enumerate(events):
            print(f"è®°å½• {i+1}:")
            print(f"  æ—¶é—´: {event.get('@timestamp')}")
            print(f"  åŸå§‹æ¶ˆæ¯: {event.get('message', '')[:100]}...")
            
            # æ£€æŸ¥è§£æå‡ºçš„å­—æ®µ
            parsed_fields = [k for k in event.keys() if not k.startswith('@') and k != 'message']
            print(f"  è§£æå­—æ®µ: {', '.join(parsed_fields)}")
            
        return events
    else:
        print(f"è·å–å¤±è´¥: {results.get('message')}")
        return []
```

**å“åº”æ ¼å¼**:
```json
{
  "ok": true,
  "events": [
    {
      "@timestamp": "2024-12-25T10:00:00.000Z",
      "message": "åŸå§‹æ—¥å¿—",
      "parsed_field1": "value1",
      "parsed_field2": "value2",
      "_parsed_time": "2024-12-25 10:00:15"
    }
  ],
  "count": 1,
  "message": "æˆåŠŸè·å– 1 æ¡è§£æè®°å½•"
}
```

### ğŸ“‹ **4. è·å– Logstash æ—¥å¿—**

**ç«¯ç‚¹**: `GET /logstash_logs`

**åŠŸèƒ½**: è·å– Logstash è¿è¡Œæ—¥å¿—ï¼Œç”¨äºè°ƒè¯•

**AI è°ƒç”¨ç¤ºä¾‹**:
```python
def get_logstash_logs():
    url = "http://localhost:19000/logstash_logs"
    response = requests.get(url)
    return response.json()

def check_for_errors():
    logs_result = get_logstash_logs()
    
    if logs_result["ok"]:
        logs = logs_result["logs"]
        
        # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
        error_lines = [line for line in logs.split('\n') if 'ERROR' in line.upper()]
        warning_lines = [line for line in logs.split('\n') if 'WARN' in line.upper()]
        
        if error_lines:
            print("å‘ç°é”™è¯¯:")
            for error in error_lines[-5:]:  # æœ€è¿‘ 5 ä¸ªé”™è¯¯
                print(f"  {error}")
                
        if warning_lines:
            print("å‘ç°è­¦å‘Š:")
            for warning in warning_lines[-3:]:  # æœ€è¿‘ 3 ä¸ªè­¦å‘Š
                print(f"  {warning}")
                
        return len(error_lines) == 0  # è¿”å›æ˜¯å¦æ— é”™è¯¯
    
    return False
```

### ğŸ—‘ï¸ **5. æ¸…ç©ºè§£æç»“æœ**

**ç«¯ç‚¹**: `POST /clear_results`

**åŠŸèƒ½**: æ¸…ç©ºå†å²è§£æç»“æœï¼Œé‡æ–°å¼€å§‹æµ‹è¯•

**AI è°ƒç”¨ç¤ºä¾‹**:
```python
def clear_results():
    url = "http://localhost:19000/clear_results"
    response = requests.post(url)
    return response.json()

# åœ¨æ–°æµ‹è¯•å‰æ¸…ç©ºå†å²æ•°æ®
clear_results()
```

---

## ğŸ¤– å®Œæ•´çš„ AI é›†æˆç±»

```python
import requests
import time
import json
from typing import Dict, List, Optional, Union

class LogstashTestService:
    """
    Logstash æµ‹è¯•æœåŠ¡ AI å®¢æˆ·ç«¯
    ä¸“ä¸º AI è‡ªåŠ¨åŒ–è°ƒç”¨è®¾è®¡
    """
    
    def __init__(self, base_url: str = "http://localhost:19000"):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/x-www-form-urlencoded'
        })
    
    def health_check(self) -> bool:
        """æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€"""
        try:
            response = self.session.get(f"{self.base_url}/get_parsed_results", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def save_filter(self, filter_content: str) -> Dict:
        """ä¿å­˜ Filter è§„åˆ™"""
        data = {"filter": filter_content}
        response = self.session.post(f"{self.base_url}/save_filter", data=data)
        return response.json()
    
    def send_test_log(self, logs: str, is_json: bool = False) -> Dict:
        """å‘é€æµ‹è¯•æ—¥å¿—"""
        data = {"logs": logs}
        if is_json:
            data["is_json"] = "1"
        
        response = self.session.post(f"{self.base_url}/test", data=data)
        return response.json()
    
    def get_parsed_results(self) -> Dict:
        """è·å–è§£æç»“æœ"""
        response = self.session.get(f"{self.base_url}/get_parsed_results")
        return response.json()
    
    def get_logstash_logs(self) -> Dict:
        """è·å– Logstash æ—¥å¿—"""
        response = self.session.get(f"{self.base_url}/logstash_logs")
        return response.json()
    
    def clear_results(self) -> Dict:
        """æ¸…ç©ºè§£æç»“æœ"""
        response = self.session.post(f"{self.base_url}/clear_results")
        return response.json()
    
    def test_filter_with_logs(self, filter_content: str, test_logs: List[str], 
                             is_json: bool = False, wait_time: int = 3) -> Dict:
        """
        å®Œæ•´çš„æµ‹è¯•å·¥ä½œæµï¼šä¿å­˜ filter -> å‘é€æ—¥å¿— -> è·å–ç»“æœ
        
        Args:
            filter_content: Filter è§„åˆ™å†…å®¹
            test_logs: æµ‹è¯•æ—¥å¿—åˆ—è¡¨
            is_json: æ˜¯å¦ä¸º JSON æ ¼å¼æ—¥å¿—
            wait_time: ç­‰å¾…çƒ­é‡è½½æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            åŒ…å«æµ‹è¯•ç»“æœçš„å­—å…¸
        """
        result = {
            "success": False,
            "steps": {},
            "parsed_events": [],
            "errors": []
        }
        
        try:
            # 1. å¥åº·æ£€æŸ¥
            if not self.health_check():
                result["errors"].append("æœåŠ¡ä¸å¯ç”¨")
                return result
            result["steps"]["health_check"] = "âœ… æœåŠ¡å¯ç”¨"
            
            # 2. æ¸…ç©ºå†å²ç»“æœ
            clear_resp = self.clear_results()
            result["steps"]["clear_results"] = clear_resp.get("message", "æ¸…ç©ºå®Œæˆ")
            
            # 3. ä¿å­˜ Filter
            save_resp = self.save_filter(filter_content)
            if not save_resp.get("ok"):
                result["errors"].append(f"Filter ä¿å­˜å¤±è´¥: {save_resp.get('message')}")
                return result
            result["steps"]["save_filter"] = save_resp.get("message")
            
            # 4. ç­‰å¾…çƒ­é‡è½½
            time.sleep(wait_time)
            result["steps"]["wait_reload"] = f"ç­‰å¾… {wait_time} ç§’çƒ­é‡è½½"
            
            # 5. å‘é€æµ‹è¯•æ—¥å¿—
            for i, log in enumerate(test_logs):
                send_resp = self.send_test_log(log, is_json)
                if send_resp.get("ok"):
                    result["steps"][f"send_log_{i+1}"] = send_resp.get("message")
                else:
                    result["errors"].append(f"æ—¥å¿— {i+1} å‘é€å¤±è´¥: {send_resp.get('message')}")
            
            # 6. è·å–è§£æç»“æœ
            parsed_resp = self.get_parsed_results()
            if parsed_resp.get("ok"):
                result["parsed_events"] = parsed_resp.get("events", [])
                result["steps"]["get_results"] = f"è·å–åˆ° {len(result['parsed_events'])} æ¡è§£æè®°å½•"
                result["success"] = True
            else:
                result["errors"].append(f"è·å–ç»“æœå¤±è´¥: {parsed_resp.get('message')}")
            
            # 7. æ£€æŸ¥é”™è¯¯æ—¥å¿—
            logs_resp = self.get_logstash_logs()
            if logs_resp.get("ok"):
                logs_content = logs_resp.get("logs", "")
                error_count = logs_content.upper().count("ERROR")
                if error_count > 0:
                    result["errors"].append(f"å‘ç° {error_count} ä¸ª Logstash é”™è¯¯")
                result["steps"]["check_logs"] = f"æ£€æŸ¥æ—¥å¿—å®Œæˆï¼Œé”™è¯¯æ•°: {error_count}"
            
        except Exception as e:
            result["errors"].append(f"æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        
        return result
    
    def analyze_parsing_effectiveness(self, events: List[Dict]) -> Dict:
        """åˆ†æè§£ææ•ˆæœ"""
        if not events:
            return {"effectiveness": 0, "details": "æ— è§£æç»“æœ"}
        
        analysis = {
            "total_events": len(events),
            "parsed_fields": {},
            "effectiveness": 0,
            "field_coverage": {},
            "details": []
        }
        
        # ç»Ÿè®¡å­—æ®µåˆ†å¸ƒ
        all_fields = set()
        for event in events:
            event_fields = [k for k in event.keys() if not k.startswith('@') and k not in ['message', 'host']]
            all_fields.update(event_fields)
            
            for field in event_fields:
                if field not in analysis["parsed_fields"]:
                    analysis["parsed_fields"][field] = 0
                analysis["parsed_fields"][field] += 1
        
        # è®¡ç®—å­—æ®µè¦†ç›–ç‡
        for field, count in analysis["parsed_fields"].items():
            coverage = (count / len(events)) * 100
            analysis["field_coverage"][field] = f"{coverage:.1f}%"
        
        # è®¡ç®—æ•´ä½“æœ‰æ•ˆæ€§
        if len(all_fields) > 0:
            analysis["effectiveness"] = min(100, len(all_fields) * 10)  # æ¯ä¸ªå­—æ®µè´¡çŒ®10åˆ†ï¼Œæœ€é«˜100åˆ†
        
        # ç”Ÿæˆè¯¦ç»†è¯´æ˜
        analysis["details"] = [
            f"å…±è§£æ {len(events)} æ¡æ—¥å¿—",
            f"æå–å­—æ®µ {len(all_fields)} ä¸ª: {', '.join(sorted(all_fields))}",
            f"è§£ææœ‰æ•ˆæ€§è¯„åˆ†: {analysis['effectiveness']}/100"
        ]
        
        return analysis

# ä½¿ç”¨ç¤ºä¾‹
def ai_test_example():
    """AI è°ƒç”¨ç¤ºä¾‹"""
    service = LogstashTestService()
    
    # æµ‹è¯• Apache æ—¥å¿—è§£æ
    apache_filter = """
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    mutate {
      rename => { "clientip" => "src_ip" }
      add_field => { "log_type" => "apache" }
    }
    """
    
    apache_logs = [
        '127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326',
        '192.168.1.100 - - [25/Dec/2023:10:00:01 +0000] "POST /api/login HTTP/1.1" 401 128'
    ]
    
    # æ‰§è¡Œæµ‹è¯•
    result = service.test_filter_with_logs(apache_filter, apache_logs)
    
    if result["success"]:
        print("âœ… æµ‹è¯•æˆåŠŸ!")
        print("\nğŸ“‹ æ‰§è¡Œæ­¥éª¤:")
        for step, message in result["steps"].items():
            print(f"  {step}: {message}")
        
        print(f"\nğŸ“Š è§£æç»“æœ: {len(result['parsed_events'])} æ¡è®°å½•")
        
        # åˆ†æè§£ææ•ˆæœ
        analysis = service.analyze_parsing_effectiveness(result["parsed_events"])
        print(f"\nğŸ“ˆ è§£æåˆ†æ:")
        for detail in analysis["details"]:
            print(f"  {detail}")
            
        print(f"\nğŸ” å­—æ®µè¦†ç›–ç‡:")
        for field, coverage in analysis["field_coverage"].items():
            print(f"  {field}: {coverage}")
            
    else:
        print("âŒ æµ‹è¯•å¤±è´¥!")
        for error in result["errors"]:
            print(f"  é”™è¯¯: {error}")

if __name__ == "__main__":
    ai_test_example()
```

---

## ğŸ¯ AI ä½¿ç”¨åœºæ™¯å’Œæ¨¡å¼

### ğŸ“Š **1. æ—¥å¿—æ ¼å¼éªŒè¯**

```python
def validate_log_format(service, log_samples, expected_fields):
    """éªŒè¯æ—¥å¿—æ ¼å¼æ˜¯å¦èƒ½æ­£ç¡®è§£æå‡ºæœŸæœ›å­—æ®µ"""
    
    # ä½¿ç”¨é€šç”¨ grok æ¨¡å¼
    generic_filter = 'grok { match => { "message" => "%{GREEDYDATA:content}" } }'
    
    result = service.test_filter_with_logs(generic_filter, log_samples)
    
    if result["success"]:
        # æ£€æŸ¥æ˜¯å¦è§£æå‡ºæœŸæœ›å­—æ®µ
        events = result["parsed_events"]
        found_fields = set()
        
        for event in events:
            found_fields.update(event.keys())
        
        missing_fields = set(expected_fields) - found_fields
        extra_fields = found_fields - set(expected_fields) - {'@timestamp', 'message', 'host'}
        
        return {
            "valid": len(missing_fields) == 0,
            "found_fields": list(found_fields),
            "missing_fields": list(missing_fields),
            "extra_fields": list(extra_fields)
        }
    
    return {"valid": False, "error": result["errors"]}
```

### ğŸ”§ **2. Filter è§„åˆ™ä¼˜åŒ–**

```python
def optimize_filter_rules(service, base_filter, test_logs, optimization_goals):
    """åŸºäºæµ‹è¯•ç»“æœä¼˜åŒ– Filter è§„åˆ™"""
    
    results = []
    
    # æµ‹è¯•åŸºç¡€è§„åˆ™
    base_result = service.test_filter_with_logs(base_filter, test_logs)
    results.append({"type": "base", "filter": base_filter, "result": base_result})
    
    # å°è¯•ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
    optimizations = [
        # æ·»åŠ å­—æ®µé‡å‘½å
        base_filter + '\nmutate { rename => { "clientip" => "src_ip" } }',
        
        # æ·»åŠ å­—æ®µç±»å‹è½¬æ¢
        base_filter + '\nmutate { convert => { "response" => "integer", "bytes" => "integer" } }',
        
        # æ·»åŠ æ¡ä»¶å¤„ç†
        base_filter + '\nif [response] >= 400 { mutate { add_tag => ["error"] } }'
    ]
    
    for i, opt_filter in enumerate(optimizations):
        opt_result = service.test_filter_with_logs(opt_filter, test_logs)
        results.append({"type": f"optimization_{i+1}", "filter": opt_filter, "result": opt_result})
    
    # åˆ†ææœ€ä½³è§„åˆ™
    best_result = max(results, key=lambda x: len(x["result"].get("parsed_events", [])))
    
    return {
        "best_filter": best_result["filter"],
        "all_results": results,
        "recommendation": f"æ¨èä½¿ç”¨ {best_result['type']} è§„åˆ™"
    }
```

### ğŸ§ª **3. æ‰¹é‡æ—¥å¿—æµ‹è¯•**

```python
def batch_log_testing(service, log_samples_by_type):
    """æ‰¹é‡æµ‹è¯•ä¸åŒç±»å‹çš„æ—¥å¿—"""
    
    test_results = {}
    
    # é¢„å®šä¹‰çš„ Filter æ¨¡æ¿
    filter_templates = {
        "apache": 'grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }',
        "json": 'json { source => "message" }',
        "syslog": 'grok { match => { "message" => "%{SYSLOGTIMESTAMP:timestamp} %{IPORHOST:host} %{PROG:program}: %{GREEDYDATA:log_message}" } }'
    }
    
    for log_type, log_samples in log_samples_by_type.items():
        print(f"\nğŸ§ª æµ‹è¯• {log_type} æ—¥å¿—ç±»å‹...")
        
        if log_type in filter_templates:
            filter_rule = filter_templates[log_type]
            is_json = log_type == "json"
            
            result = service.test_filter_with_logs(filter_rule, log_samples, is_json=is_json)
            
            # åˆ†æç»“æœ
            if result["success"]:
                analysis = service.analyze_parsing_effectiveness(result["parsed_events"])
                test_results[log_type] = {
                    "success": True,
                    "events_count": len(result["parsed_events"]),
                    "effectiveness": analysis["effectiveness"],
                    "fields": list(analysis["parsed_fields"].keys())
                }
            else:
                test_results[log_type] = {
                    "success": False,
                    "errors": result["errors"]
                }
        else:
            test_results[log_type] = {
                "success": False,
                "errors": [f"æœªæ‰¾åˆ° {log_type} ç±»å‹çš„ Filter æ¨¡æ¿"]
            }
    
    return test_results
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹å’Œæœ€ä½³å®è·µ

### ğŸš¨ **é”™è¯¯å¤„ç†**

```python
def robust_api_call(func, *args, **kwargs):
    """å¥å£®çš„ API è°ƒç”¨åŒ…è£…å™¨"""
    max_retries = 3
    retry_delay = 1
    
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except requests.exceptions.ConnectionError:
            if attempt < max_retries - 1:
                print(f"è¿æ¥å¤±è´¥ï¼Œ{retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
                retry_delay *= 2
            else:
                raise Exception("æœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
        except requests.exceptions.Timeout:
            if attempt < max_retries - 1:
                print(f"è¯·æ±‚è¶…æ—¶ï¼Œ{retry_delay} ç§’åé‡è¯•...")
                time.sleep(retry_delay)
            else:
                raise Exception("æœåŠ¡å“åº”è¶…æ—¶")
        except Exception as e:
            raise Exception(f"API è°ƒç”¨å¼‚å¸¸: {str(e)}")
```

### â±ï¸ **æ€§èƒ½ä¼˜åŒ–**

```python
# 1. ä½¿ç”¨è¿æ¥æ± 
session = requests.Session()
adapter = requests.adapters.HTTPAdapter(pool_connections=10, pool_maxsize=20)
session.mount('http://', adapter)

# 2. è®¾ç½®åˆç†çš„è¶…æ—¶
timeout_config = {
    "save_filter": 10,    # Filter ä¿å­˜å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
    "test": 5,           # å‘é€æ—¥å¿—
    "get_results": 3,    # è·å–ç»“æœ
    "logs": 8            # è·å–æ—¥å¿—å¯èƒ½è¾ƒæ…¢
}

# 3. æ‰¹é‡å¤„ç†
def batch_send_logs(service, logs, batch_size=5):
    """æ‰¹é‡å‘é€æ—¥å¿—ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚"""
    results = []
    for i in range(0, len(logs), batch_size):
        batch = logs[i:i+batch_size]
        batch_content = '\n'.join(batch)
        result = service.send_test_log(batch_content)
        results.append(result)
        time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿé¿å…è¿‡è½½
    return results
```

### ğŸ” **è°ƒè¯•æ”¯æŒ**

```python
import logging

# é…ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

class DebugLogstashService(LogstashTestService):
    """å¸¦è°ƒè¯•åŠŸèƒ½çš„æœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.debug = True
    
    def _debug_log(self, message):
        if self.debug:
            logger.debug(f"[LogstashService] {message}")
    
    def save_filter(self, filter_content):
        self._debug_log(f"ä¿å­˜ Filter: {len(filter_content)} å­—ç¬¦")
        result = super().save_filter(filter_content)
        self._debug_log(f"ä¿å­˜ç»“æœ: {result.get('message')}")
        return result
    
    def send_test_log(self, logs, is_json=False):
        self._debug_log(f"å‘é€æ—¥å¿—: {len(logs)} å­—ç¬¦, JSON={is_json}")
        result = super().send_test_log(logs, is_json)
        self._debug_log(f"å‘é€ç»“æœ: {result.get('message')}")
        return result
```

---

## ğŸ“‹ å®Œæ•´ç¤ºä¾‹è„šæœ¬

```python
#!/usr/bin/env python3
"""
å®Œæ•´çš„ AI é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Logstash æµ‹è¯•æœåŠ¡è¿›è¡Œè‡ªåŠ¨åŒ–æ—¥å¿—è§£ææµ‹è¯•
"""

import sys
from logstash_service import LogstashTestService

def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„æµ‹è¯•æµç¨‹"""
    
    print("ğŸ¤– AI é›†æˆæµ‹è¯•å¼€å§‹...")
    
    # åˆå§‹åŒ–æœåŠ¡
    service = LogstashTestService()
    
    # å¥åº·æ£€æŸ¥
    if not service.health_check():
        print("âŒ æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ Logstash æµ‹è¯•æœåŠ¡çŠ¶æ€")
        sys.exit(1)
    
    print("âœ… æœåŠ¡çŠ¶æ€æ­£å¸¸")
    
    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "name": "Apache è®¿é—®æ—¥å¿—",
            "filter": 'grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }',
            "logs": [
                '127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326',
                '192.168.1.100 - user [25/Dec/2023:10:00:01 +0000] "POST /api/login HTTP/1.1" 401 128'
            ],
            "is_json": False
        },
        {
            "name": "JSON åº”ç”¨æ—¥å¿—",
            "filter": 'json { source => "message" } if [level] { mutate { uppercase => ["level"] } }',
            "logs": [
                '{"timestamp": "2023-12-25T10:00:00Z", "level": "info", "message": "ç”¨æˆ·ç™»å½•æˆåŠŸ", "user_id": 12345}',
                '{"timestamp": "2023-12-25T10:00:01Z", "level": "error", "message": "æ•°æ®åº“è¿æ¥å¤±è´¥", "error_code": 500}'
            ],
            "is_json": True
        }
    ]
    
    # æ‰§è¡Œæµ‹è¯•
    all_results = []
    
    for test_case in test_cases:
        print(f"\nğŸ§ª æµ‹è¯•: {test_case['name']}")
        print(f"Filter: {test_case['filter'][:50]}...")
        
        result = service.test_filter_with_logs(
            test_case['filter'],
            test_case['logs'],
            is_json=test_case['is_json']
        )
        
        if result["success"]:
            print("âœ… æµ‹è¯•æˆåŠŸ")
            
            # åˆ†æç»“æœ
            analysis = service.analyze_parsing_effectiveness(result["parsed_events"])
            print(f"ğŸ“Š è§£ææ•ˆæœ: {analysis['effectiveness']}/100")
            print(f"ğŸ“‹ æå–å­—æ®µ: {', '.join(analysis['parsed_fields'].keys())}")
            
            all_results.append({
                "test_case": test_case['name'],
                "success": True,
                "analysis": analysis
            })
        else:
            print("âŒ æµ‹è¯•å¤±è´¥")
            for error in result["errors"]:
                print(f"  é”™è¯¯: {error}")
            
            all_results.append({
                "test_case": test_case['name'],
                "success": False,
                "errors": result["errors"]
            })
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print("\n" + "="*50)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("="*50)
    
    success_count = sum(1 for r in all_results if r["success"])
    total_count = len(all_results)
    
    print(f"æ€»æµ‹è¯•æ•°: {total_count}")
    print(f"æˆåŠŸæ•°: {success_count}")
    print(f"æˆåŠŸç‡: {(success_count/total_count)*100:.1f}%")
    
    for result in all_results:
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {result['test_case']}")
        
        if result["success"]:
            analysis = result["analysis"]
            print(f"   è§£ææ•ˆæœ: {analysis['effectiveness']}/100")
            print(f"   å­—æ®µæ•°é‡: {len(analysis['parsed_fields'])}")
        else:
            print(f"   é”™è¯¯: {'; '.join(result['errors'])}")
    
    print("\nğŸ‰ AI é›†æˆæµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
```

---

## ğŸ”— ç›¸å…³èµ„æº

- **é¡¹ç›®ä¸»æ–‡æ¡£**: [README.md](README.md)
- **æœåŠ¡å¯åŠ¨**: `./start.sh`
- **Web ç•Œé¢**: http://localhost:19000
- **API åŸºç¡€åœ°å€**: http://localhost:19000

---

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

å¦‚æœ AI åœ¨è°ƒç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š

1. **æ£€æŸ¥æœåŠ¡çŠ¶æ€**: `curl http://localhost:19000/get_parsed_results`
2. **æŸ¥çœ‹æœåŠ¡æ—¥å¿—**: `docker compose logs -f`
3. **é‡å¯æœåŠ¡**: `docker compose restart`
4. **æ£€æŸ¥ç½‘ç»œè¿æ¥**: ç¡®ä¿ç«¯å£ 19000 å¯è®¿é—®

**å¸¸è§é—®é¢˜**:
- æœåŠ¡ä¸å“åº” â†’ æ£€æŸ¥ Docker å®¹å™¨çŠ¶æ€
- è§£æç»“æœä¸ºç©º â†’ æ£€æŸ¥ Filter è¯­æ³•å’Œæ—¥å¿—æ ¼å¼åŒ¹é…
- çƒ­é‡è½½å¤±è´¥ â†’ ç­‰å¾…æ›´é•¿æ—¶é—´æˆ–æ‰‹åŠ¨é‡å¯æœåŠ¡

---

*æœ¬æ–‡æ¡£ä¸“ä¸º AI ç³»ç»Ÿè®¾è®¡ï¼Œæä¾›äº†å®Œæ•´çš„è°ƒç”¨æŒ‡å—å’Œç¤ºä¾‹ä»£ç ã€‚*
