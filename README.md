# ğŸš€ Logstash è§„åˆ™æµ‹è¯•å·¥å…·

<div align="center">

[![GitHub release](https://img.shields.io/github/release/username/logstash-lab.svg)](https://github.com/username/logstash-lab/releases)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://docker.com/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**ä¸€ä¸ªç°ä»£åŒ–çš„ Logstash è§„åˆ™æµ‹è¯•å’Œè°ƒè¯•å·¥å…·**

æä¾›ç›´è§‚çš„ Web ç•Œé¢ï¼Œæ”¯æŒå®æ—¶ç¼–è¾‘ã€æµ‹è¯•å’Œè°ƒè¯• Logstash filter è§„åˆ™

[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [åŠŸèƒ½æ¼”ç¤º](#-åŠŸèƒ½æ¼”ç¤º) â€¢ [ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—) â€¢ [API æ–‡æ¡£](#-api-æ–‡æ¡£)

</div>

---

## ğŸ“¸ åŠŸèƒ½æ¼”ç¤º

### ä¸»ç•Œé¢æ¦‚è§ˆ
![Logstash æµ‹è¯•å·¥å…·ä¸»ç•Œé¢](./docs/screenshots/main-interface.jpg)

### æ ¸å¿ƒåŠŸèƒ½
- ğŸ¯ **æ™ºèƒ½ Filter ç¼–è¾‘å™¨**: æ”¯æŒè¯­æ³•é«˜äº®å’Œè‡ªåŠ¨å®Œæˆ
- âš¡ **å®æ—¶çƒ­é‡è½½**: è§„åˆ™ä¿®æ”¹ 3 ç§’å†…è‡ªåŠ¨ç”Ÿæ•ˆ
- ğŸ” **è§£æç»“æœæŸ¥çœ‹**: JSON æ ¼å¼ç¾åŒ–æ˜¾ç¤ºï¼Œæ”¯æŒä¸€é”®è·å–
- ğŸ“Š **ç¤ºä¾‹æ¨¡æ¿åº“**: å†…ç½®å¸¸ç”¨æ—¥å¿—æ ¼å¼æ¨¡æ¿
- ğŸ”§ **æ—¥å¿—è°ƒè¯•**: å®æ—¶æŸ¥çœ‹ Logstash è¿è¡Œæ—¥å¿—
- ğŸ’¾ **é…ç½®æŒä¹…åŒ–**: è‡ªåŠ¨ä¿å­˜ç”¨æˆ·è¾“å…¥ï¼Œåˆ·æ–°ä¸ä¸¢å¤±
- ğŸŒŠ **MCP æœåŠ¡å™¨**: ä¸º AI æä¾› SSE æµå¼è°ƒç”¨æ¥å£ï¼Œæ”¯æŒå®æ—¶è¿›åº¦åé¦ˆå’Œæ–‡ä»¶ä¸Šä¼ 

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ¯ **æ™ºèƒ½åŒ– Metadata ç®¡ç†**
- **è‡ªåŠ¨æ¡ä»¶åˆ¤æ–­æ›¿æ¢**: æ— è®ºè¾“å…¥ä»»ä½• `if "xxx" == [@metadata][type]` æ¡ä»¶ï¼Œè‡ªåŠ¨ç»Ÿä¸€ä¸º `if "test" == [@metadata][type]`
- **å…ƒæ•°æ®è‡ªåŠ¨è®¾ç½®**: ç³»ç»Ÿè‡ªåŠ¨è®¾ç½® `[@metadata][type] = "test"`ï¼Œç¡®ä¿é…ç½®ä¸€è‡´æ€§
- **ç®€åŒ–é…ç½®ç®¡ç†**: ç”¨æˆ·ä¸“æ³¨ç¼–å†™ filter é€»è¾‘ï¼Œæ— éœ€å…³å¿ƒæ¡ä»¶åˆ¤æ–­å’Œå…ƒæ•°æ®åŒ¹é…

### ğŸ”§ **å…ˆè¿›çš„ç¼–è¾‘ä½“éªŒ**
- **å®½å±è‡ªé€‚åº”å¸ƒå±€**: å……åˆ†åˆ©ç”¨å±å¹•ç©ºé—´ï¼Œæ”¯æŒå¤§å±æ˜¾ç¤º
- **å®æ—¶é…ç½®éªŒè¯**: ä¿å­˜æ—¶è‡ªåŠ¨æ£€æŸ¥ Logstash é…ç½®è¯­æ³•
- **çƒ­é‡è½½æœºåˆ¶**: é…ç½®ä¿®æ”¹å 3 ç§’å†…è‡ªåŠ¨é‡æ–°åŠ è½½
- **é…ç½®æŒä¹…åŒ–**: ä½¿ç”¨ localStorage ä¿å­˜ç”¨æˆ·è¾“å…¥ï¼Œé¡µé¢åˆ·æ–°ä¸ä¸¢å¤±

### ğŸ“Š **å…¨é¢çš„è°ƒè¯•åŠŸèƒ½**  
- **è§£æç»“æœå®æ—¶æŸ¥çœ‹**: å‘é€æ—¥å¿—åç«‹å³æ˜¾ç¤ºè§£æç»“æœ
- **å†å²è®°å½•è·å–**: ä¸€é”®è·å–æœ€æ–° 50 æ¡è§£æè®°å½•
- **JSON ç¾åŒ–æ˜¾ç¤º**: æ ¼å¼åŒ–è¾“å‡ºï¼Œæ˜“äºé˜…è¯»å’Œåˆ†æ
- **Logstash æ—¥å¿—æŸ¥çœ‹**: å†…ç½®æ—¥å¿—æŸ¥çœ‹åŠŸèƒ½ï¼Œå¿«é€Ÿå®šä½é—®é¢˜

### ğŸš€ **å¼€å‘å‹å¥½ç‰¹æ€§**
- **Docker åŒ–éƒ¨ç½²**: ä¸€é”®å¯åŠ¨ï¼Œæ— éœ€å¤æ‚ç¯å¢ƒé…ç½®
- **å¼€å‘æ¨¡å¼æ”¯æŒ**: ä»£ç ä¿®æ”¹è‡ªåŠ¨é‡è½½ï¼Œé€‚åˆå¼€å‘è°ƒè¯•
- **RESTful API**: æä¾›å®Œæ•´ API æ¥å£ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–æµ‹è¯•
- **è·¨å¹³å°æ”¯æŒ**: Linuxã€macOSã€Windows å…¨å¹³å°æ”¯æŒ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç³»ç»Ÿè¦æ±‚
- Docker 20.0+
- Docker Compose 2.0+
- å¯ç”¨å†…å­˜ 1GB+

### ä¸€é”®å¯åŠ¨

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/username/logstash-lab.git
cd logstash-lab

# 2. å¯åŠ¨æœåŠ¡ï¼ˆæ¨èï¼‰
./start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
sudo docker compose up -d --build
```

### è®¿é—®æœåŠ¡

```bash
# Web ç•Œé¢
http://localhost:19000

# MCP æœåŠ¡å™¨
http://localhost:19001

# å¥åº·æ£€æŸ¥
curl http://localhost:19001/tools/health_check

# æœåŠ¡çŠ¶æ€æ£€æŸ¥
sudo docker compose ps
```

### ğŸ”— MCP å®¢æˆ·ç«¯é…ç½®

ä¸º AI å®¢æˆ·ç«¯ï¼ˆå¦‚ Cursorã€Claude Desktopï¼‰é…ç½® MCP è¿æ¥ï¼š

#### æœ€ç®€å•é…ç½® (æ¨è)
```json
{
  "mcpServers": {
    "logstash-test": {
      "url": "http://localhost:19001/mcp",
      "description": "Logstash è§„åˆ™æµ‹è¯•å’Œè°ƒè¯•å·¥å…·"
    }
  }
}
```

#### å…¼å®¹æ€§é…ç½®
```json
{
  "mcpServers": {
    "logstash-test": {
      "command": "curl",
      "args": [
        "-s", "-X", "POST", 
        "http://localhost:19001/mcp",
        "-H", "Content-Type: application/json",
        "-d", "@-"
      ],
      "description": "Logstash è§„åˆ™æµ‹è¯•å’Œè°ƒè¯•å·¥å…·"
    }
  }
}
```

**é…ç½®ä½ç½®**:
- **Cursor**: `~/.cursor/mcp.json`
- **Claude Desktop (macOS)**: `~/Library/Application Support/Claude/claude_desktop_config.json`
- **Claude Desktop (Windows)**: `%APPDATA%/Claude/claude_desktop_config.json`

**ğŸ“š è¯¦ç»†é…ç½®æŒ‡å—**: æŸ¥çœ‹ [MCP æœåŠ¡å™¨æ–‡æ¡£](mcp_server/README.md)

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºæœ¬å·¥ä½œæµ

#### ğŸŒŸ æ¨èæ–¹å¼ï¼šPipeline æ–‡ä»¶ä¸Šä¼ 

1. **ğŸ“ å‡†å¤‡ Pipeline é…ç½®æ–‡ä»¶**
   ```logstash
   # your_pipeline.conf
   input {
     udp {
       port => 18136
       codec => line {}
       add_field => { "[@metadata][type]" => "bomgar" }
     }
   }
   
   filter {
     if "bomgar" == [@metadata][type] {
       grok {
         match => { "message" => "<%{POSINT:syslog_pri}>%{POSINT:syslog_ver} %{DATA:syslog_timestamp} %{GREEDYDATA:content}" }
       }
       # æ›´å¤š filter è§„åˆ™...
     }
   }
   
   output {
     kafka {
       bootstrap_servers => "localhost:9092"
       topic_id => "logs"
     }
   }
   ```

2. **ğŸš€ ä¸Šä¼ å¹¶è‡ªåŠ¨åº”ç”¨**
   ```bash
   # æ–¹å¼ä¸€ï¼šæ–‡ä»¶ä¸Šä¼ ï¼ˆæœ€æ¨èï¼‰
   curl -X POST http://localhost:19000/upload_pipeline -F 'file=@your_pipeline.conf'
   
   # æ–¹å¼äºŒï¼šWeb ç•Œé¢ä¸Šä¼ 
   # è®¿é—® http://localhost:19000 â†’ Pipeline æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ â†’ é€‰æ‹©æ–‡ä»¶æˆ–ç²˜è´´å†…å®¹
   ```

#### ğŸ”§ ä¼ ç»Ÿæ–¹å¼ï¼šç›´æ¥ç¼–è¾‘ Filter

1. **ğŸ“ ç¼–è¾‘ Filter è§„åˆ™**
   ```logstash
   # è¾“å…¥æ‚¨çš„ filter è§„åˆ™ï¼Œæ”¯æŒä»»ä½•æ¡ä»¶åˆ¤æ–­æ ¼å¼
   filter {
     if "apache" == [@metadata][type] {  # ä¼šè‡ªåŠ¨æ›¿æ¢ä¸º "test"
       grok {
         match => { "message" => "%{COMBINEDAPACHELOG}" }
       }
       mutate {
         rename => { "clientip" => "src_ip" }
       }
     }
   }
   ```

2. **ğŸ’¾ ä¿å­˜å¹¶è‡ªåŠ¨é‡è½½**
   - ç‚¹å‡»"ä¿å­˜ Filter"æŒ‰é’®
   - ç³»ç»Ÿè‡ªåŠ¨é‡è½½é…ç½®ï¼ˆ3ç§’å†…ç”Ÿæ•ˆï¼‰
   - è‡ªåŠ¨è®¾ç½®æ­£ç¡®çš„å…ƒæ•°æ®ç±»å‹

#### ğŸ§ª å…±åŒæ­¥éª¤ï¼šæµ‹è¯•å’ŒéªŒè¯

3. **ğŸ“ è¾“å…¥æµ‹è¯•æ•°æ®**
   ```bash
   # Web ç•Œé¢ï¼šç›´æ¥åœ¨"æµ‹è¯•æ—¥å¿—"åŒºåŸŸè¾“å…¥
   127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326
   
   # API è°ƒç”¨ï¼šæ¨èä½¿ç”¨ --data-urlencode
   curl -X POST http://localhost:19000/test \
     -H "Content-Type: application/x-www-form-urlencoded" \
     --data-urlencode "logs=<133>1 2025-09-10T12:08:07+08:00 SGPDRT-VSBRS01 BG 16703 - [meta sequenceId=\"46\"] session_data"
   ```

4. **ğŸš€ å‘é€å¹¶æŸ¥çœ‹ç»“æœ**
   - **Web ç•Œé¢**: ç‚¹å‡»"å‘é€å¹¶æŸ¥çœ‹è§£æç»“æœ"æŒ‰é’®
   - **API è°ƒç”¨**: ä½¿ç”¨ `/get_parsed_results` æ¥å£
   - å®æ—¶æŸ¥çœ‹ JSON æ ¼å¼çš„è§£æç»“æœ
   - ä½¿ç”¨"è·å–è§£æåçš„è®°å½•"æŸ¥çœ‹å†å²è®°å½•

#### â­ æœ€ä½³å®è·µ

- **é¦–é€‰ Pipeline æ–‡ä»¶ä¸Šä¼ **: é¿å… URL ç¼–ç å’Œæ ¼å¼é—®é¢˜
- **ä½¿ç”¨ `--data-urlencode`**: å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚ `+` å·ï¼‰
- **æµ‹è¯•å‰æ¸…ç©ºç»“æœ**: ç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§
- **æŸ¥çœ‹ Logstash æ—¥å¿—**: åŠæ—¶å‘ç°é…ç½®é”™è¯¯

### å†…ç½®ç¤ºä¾‹æ¨¡æ¿

| æ¨¡æ¿ç±»å‹ | æè¿° | é€‚ç”¨åœºæ™¯ |
|---------|------|----------|
| **Apache æ—¥å¿—** | COMBINEDAPACHELOG æ ¼å¼ | Web æœåŠ¡å™¨è®¿é—®æ—¥å¿— |
| **JSON æ—¥å¿—** | ç»“æ„åŒ– JSON æ ¼å¼ | åº”ç”¨ç¨‹åºæ—¥å¿— |
| **Syslog** | æ ‡å‡† syslog æ ¼å¼ | ç³»ç»Ÿæ—¥å¿— |
| **è‡ªå®šä¹‰æ ¼å¼** | ç”¨æˆ·è‡ªå®šä¹‰è§„åˆ™ | ç‰¹æ®Šæ ¼å¼æ—¥å¿— |

### é«˜çº§åŠŸèƒ½

#### ğŸ” **è°ƒè¯•å’Œæ’é”™**

```bash
# æŸ¥çœ‹å®æ—¶æ—¥å¿—
sudo docker compose logs -f logstash

# æŸ¥çœ‹è§£æç»“æœ
tail -f data/out/events.ndjson

# æ£€æŸ¥é…ç½®è¯­æ³•
sudo docker compose exec logstash bin/logstash --config.test_and_exit
```

#### âš™ï¸ **è‡ªå®šä¹‰é…ç½®**

```yaml
# docker-compose.yml è‡ªå®šä¹‰ç«¯å£
services:
  web:
    ports:
      - "8080:19000"  # ä¿®æ”¹ Web ç«¯å£
  logstash:
    environment:
      - LS_JAVA_OPTS=-Xms1g -Xmx2g  # è°ƒæ•´å†…å­˜
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```
logstash-lab/
â”œâ”€â”€ ğŸ“„ docker-compose.yml          # Docker æœåŠ¡ç¼–æ’
â”œâ”€â”€ ğŸš€ start.sh                    # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ ğŸŒ web/                        # Web åº”ç”¨
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile              # Web æœåŠ¡å®¹å™¨
â”‚   â”œâ”€â”€ ğŸ app.py                  # Flask åç«¯åº”ç”¨
â”‚   â””â”€â”€ ğŸ“± templates/index.html    # å‰ç«¯ç•Œé¢
â”œâ”€â”€ âš™ï¸ logstash/                   # Logstash é…ç½®
â”‚   â”œâ”€â”€ ğŸ“ logstash.yml            # ä¸»é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ ğŸ”§ pipeline/test.conf      # Pipeline è§„åˆ™
â”œâ”€â”€ ğŸ’¾ data/out/                   # è¾“å‡ºæ•°æ®
â”‚   â””â”€â”€ ğŸ“Š events.ndjson           # è§£æç»“æœ
â””â”€â”€ ğŸ“š docs/                       # æ–‡æ¡£å’Œæˆªå›¾
    â””â”€â”€ ğŸ“¸ screenshots/            # åŠŸèƒ½æˆªå›¾
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

| ç»„ä»¶ | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬ | ä½œç”¨ |
|------|----------|------|------|
| **åç«¯æ¡†æ¶** | Flask + Waitress | 2.3+ | Web æœåŠ¡å’Œ API |
| **æ—¥å¿—å¤„ç†** | Logstash | 8.14.2 | è§„åˆ™è§£æå¼•æ“ |
| **å‰ç«¯æŠ€æœ¯** | HTML5 + CSS3 + JS | ES6+ | ç”¨æˆ·ç•Œé¢ |
| **å®¹å™¨åŒ–** | Docker + Compose | 20.0+ | æœåŠ¡ç¼–æ’ |
| **æ•°æ®å­˜å‚¨** | NDJSON Files | - | è½»é‡çº§æ•°æ®å­˜å‚¨ |

## ğŸ“‹ API æ–‡æ¡£

### æ ¸å¿ƒ API ç«¯ç‚¹æ¦‚è§ˆ

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | çŠ¶æ€ç  |
|------|------|------|--------|
| `/upload_pipeline` | POST | ğŸŒŸ **æ¨è** ä¸Šä¼ å®Œæ•´ pipeline æ–‡ä»¶å¹¶è‡ªåŠ¨æå– filter | 200 |
| `/save_filter` | POST | ä¿å­˜å’Œæ›´æ–° filter é…ç½® | 200 |
| `/test` | POST | å‘é€æµ‹è¯•æ—¥å¿—å¹¶è·å–è§£æç»“æœ | 200 |
| `/get_parsed_results` | GET | è·å–æœ€æ–°çš„è§£æè®°å½• | 200 |
| `/logstash_logs` | GET | è·å– Logstash è¿è¡Œæ—¥å¿— | 200 |
| `/clear_results` | POST | æ¸…ç©ºè§£æç»“æœæ–‡ä»¶ | 200 |

---

### ğŸŒŸ 1. Pipeline æ–‡ä»¶ä¸Šä¼ æ¥å£ï¼ˆæ¨èï¼‰

**ç«¯ç‚¹**: `/upload_pipeline`  
**æ–¹æ³•**: `POST`  
**æè¿°**: ä¸Šä¼ å®Œæ•´çš„ Logstash pipeline é…ç½®æ–‡ä»¶ï¼Œç³»ç»Ÿè‡ªåŠ¨æå– filter å—å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒ

#### ä¼˜åŠ¿ç‰¹æ€§

- âœ… **å®Œå…¨é¿å… URL ç¼–ç é—®é¢˜**: ä¸ä¼šå‡ºç° `+` å·å˜ç©ºæ ¼ç­‰ç¼–ç é—®é¢˜
- âœ… **ä¿æŒåŸå§‹æ ¼å¼**: è‡ªåŠ¨ä¿ç•™æ¢è¡Œç¬¦ã€ç¼©è¿›å’Œæ³¨é‡Š
- âœ… **æ™ºèƒ½è§£æ**: è‡ªåŠ¨è¯†åˆ«å’Œæå– filter å—ï¼Œæ”¯æŒå¤æ‚åµŒå¥—ç»“æ„
- âœ… **åŒé‡æ”¯æŒ**: åŒæ—¶æ”¯æŒæ–‡ä»¶ä¸Šä¼ å’Œæ–‡æœ¬å†…å®¹ç²˜è´´
- âœ… **æ— ç¼é›†æˆ**: è‡ªåŠ¨åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒï¼Œæ— éœ€é¢å¤–é…ç½®

#### è¯·æ±‚å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `file` | File | å¦* | Pipeline é…ç½®æ–‡ä»¶ (.conf/.txt) |
| `pipeline` | string | å¦* | Pipeline é…ç½®æ–‡æœ¬å†…å®¹ |

*æ³¨ï¼š`file` å’Œ `pipeline` äºŒé€‰ä¸€*

#### è¯·æ±‚ç¤ºä¾‹

```bash
# ğŸ¯ æ–¹å¼ä¸€ï¼šæ–‡ä»¶ä¸Šä¼ ï¼ˆæœ€æ¨èï¼‰
curl -X POST http://localhost:19000/upload_pipeline \
  -F 'file=@your_pipeline.conf'

# ğŸ¯ æ–¹å¼äºŒï¼šæ–‡æœ¬å†…å®¹ä¸Šä¼ 
curl -X POST http://localhost:19000/upload_pipeline \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode 'pipeline=input {
    udp {
      port => 18136
      codec => line {}
      add_field => { "[@metadata][type]" => "bomgar" }
    }
  }
  
  filter {
    if "bomgar" == [@metadata][type] {
      grok {
        match => { "message" => "<%{POSINT:syslog_pri}>%{POSINT:syslog_ver} %{DATA:syslog_timestamp} %{GREEDYDATA:content}" }
      }
      # æ›´å¤š filter è§„åˆ™...
    }
  }
  
  output {
    kafka {
      bootstrap_servers => "localhost:9092"
      topic_id => "logs"
    }
  }'

# ğŸ¯ æ–¹å¼ä¸‰ï¼šä»å·²æœ‰é…ç½®æ–‡ä»¶æå–
curl -X POST http://localhost:19000/upload_pipeline \
  -F 'file=@/etc/logstash/pipelines.d/production.conf'
```

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "message": "Pipeline å·²æˆåŠŸä¸Šä¼ å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒ",
  "extracted_filters": 1,
  "applied_filter_preview": "    if \"bomgar\" == [@metadata][type] {\n        grok {\n            match => { \"message\" => \"<%{POSINT:syslog_pri}>%{POSINT:syslog_ver}...\" }\n        }\n        # Parse bomgar specific fields...\n    }"
}
```

#### Web ç•Œé¢ä½¿ç”¨

1. è®¿é—® `http://localhost:19000`
2. åœ¨ **"Pipeline æ–‡ä»¶ä¸Šä¼ "** åŒºåŸŸï¼š
   - **æ–‡ä»¶ä¸Šä¼ **: ç‚¹å‡» "é€‰æ‹©æ–‡ä»¶" ä¸Šä¼  `.conf` æ–‡ä»¶
   - **ç›´æ¥ç²˜è´´**: ç‚¹å‡» "ç›´æ¥ç²˜è´´å†…å®¹" è¾“å…¥é…ç½®
3. ç³»ç»Ÿè‡ªåŠ¨è§£æå¹¶æ˜¾ç¤ºæå–çš„ filter é¢„è§ˆ
4. é…ç½®ç«‹å³åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒï¼Œæ— éœ€é¢å¤–æ“ä½œ

---

### ğŸ”§ 2. ç¼–è¾‘ Filter æ¥å£

**ç«¯ç‚¹**: `/save_filter`  
**æ–¹æ³•**: `POST`  
**æè¿°**: ä¿å­˜ Logstash filter é…ç½®ï¼Œæ”¯æŒæ™ºèƒ½æ¡ä»¶åˆ¤æ–­æ›¿æ¢å’Œçƒ­é‡è½½

> âš ï¸ **æ³¨æ„**: æ­¤æ¥å£å¯èƒ½é‡åˆ° URL ç¼–ç é—®é¢˜ï¼ˆå¦‚ `+` å·å˜ç©ºæ ¼ï¼‰å’Œæ¢è¡Œç¬¦å¤„ç†é—®é¢˜ã€‚**æ¨èä½¿ç”¨ `/upload_pipeline` æ¥å£**ä»¥è·å¾—æ›´å¥½çš„ä½“éªŒã€‚

#### è¯·æ±‚å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `filter` | string | æ˜¯ | Logstash filter é…ç½®å†…å®¹ |

#### è¯·æ±‚ç¤ºä¾‹

```bash
# âœ… æ¨èæ–¹å¼ï¼šä½¿ç”¨ --data-urlencode é¿å…ç¼–ç é—®é¢˜
curl -X POST http://localhost:19000/save_filter \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "filter=grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } }"

# âš ï¸ å¯èƒ½æœ‰é—®é¢˜ï¼šä½¿ç”¨ -d å¯èƒ½å¯¼è‡´ç‰¹æ®Šå­—ç¬¦ç¼–ç é”™è¯¯
curl -X POST http://localhost:19000/save_filter \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "filter=grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } }"

# âœ… æ¨èæ–¹å¼ï¼šä½¿ç”¨æ–‡ä»¶é¿å…è½¬ä¹‰é—®é¢˜
echo 'filter=grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }' > /tmp/filter.txt
curl -X POST http://localhost:19000/save_filter \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data @/tmp/filter.txt

# âŒ å¤æ‚é…ç½®å»ºè®®ä½¿ç”¨ /upload_pipeline æ¥å£
# ä»¥ä¸‹ç¤ºä¾‹å¯èƒ½å‡ºç°æ¢è¡Œç¬¦ä¸¢å¤±ç­‰é—®é¢˜
curl -X POST http://localhost:19000/save_filter \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "filter=filter {
    if \"apache\" == [@metadata][type] {
      grok {
        match => { \"message\" => \"%{COMBINEDAPACHELOG}\" }
      }
      mutate {
        rename => { \"clientip\" => \"src_ip\" }
      }
    }
  }"
```

#### URL ç¼–ç é—®é¢˜è¯´æ˜

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|----------|
| `+` å·å˜ç©ºæ ¼ | `curl -d` è‡ªåŠ¨è¿›è¡Œ URL è§£ç  | ä½¿ç”¨ `--data-urlencode` æˆ–æ‰‹åŠ¨ç¼–ç ä¸º `%2B` |
| æ¢è¡Œç¬¦ä¸¢å¤± | Web åº”ç”¨æ¢è¡Œç¬¦å¤„ç† Bug | ä½¿ç”¨ `/upload_pipeline` æ¥å£ |
| ç‰¹æ®Šå­—ç¬¦é”™è¯¯ | å¤šå±‚è½¬ä¹‰å¯¼è‡´è¯­æ³•é”™è¯¯ | ä½¿ç”¨æ–‡ä»¶ä¼ è¾“æˆ– `/upload_pipeline` |

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "message": "Filter å·²ä¿å­˜å¹¶è‡ªåŠ¨é‡è½½ (å·²è‡ªåŠ¨æ·»åŠ æ¡ä»¶åˆ¤æ–­: if \"test\" == [@metadata][type])"
}
```

#### æ™ºèƒ½åŠŸèƒ½è¯´æ˜

- **è‡ªåŠ¨æ¡ä»¶åˆ¤æ–­æ›¿æ¢**: ä»»ä½• `if "xxx" == [@metadata][type]` ä¼šè‡ªåŠ¨æ›¿æ¢ä¸º `if "test" == [@metadata][type]`
- **å…ƒæ•°æ®è‡ªåŠ¨è®¾ç½®**: ç³»ç»Ÿè‡ªåŠ¨è®¾ç½® `[@metadata][type] = "test"`
- **çƒ­é‡è½½**: é…ç½®ä¿å­˜å 3 ç§’å†…è‡ªåŠ¨ç”Ÿæ•ˆ
- **è¯­æ³•éªŒè¯**: ä¿å­˜æ—¶è‡ªåŠ¨æ£€æŸ¥ Logstash é…ç½®è¯­æ³•

---

### ğŸ“Š 3. è·å–è§£æç»“æœæ¥å£

**ç«¯ç‚¹**: `/get_parsed_results`  
**æ–¹æ³•**: `GET`  
**æè¿°**: è·å–æœ€æ–°çš„è§£æè®°å½•ï¼Œæ”¯æŒå®æ—¶æŸ¥çœ‹å¤„ç†ç»“æœ

#### è¯·æ±‚ç¤ºä¾‹

```bash
# è·å–æœ€æ–°è§£æè®°å½•
curl http://localhost:19000/get_parsed_results

# ä½¿ç”¨ jq ç¾åŒ–è¾“å‡º
curl -s http://localhost:19000/get_parsed_results | jq .

# åªè·å–è®°å½•æ•°é‡
curl -s http://localhost:19000/get_parsed_results | jq .count

# è·å–ç‰¹å®šå­—æ®µ
curl -s http://localhost:19000/get_parsed_results | jq '.events[] | {timestamp: .["@timestamp"], message: .message}'
```

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "events": [
    {
      "@timestamp": "2024-12-25T10:00:00.000Z",
      "message": "127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326",
      "clientip": "127.0.0.1",
      "verb": "GET",
      "request": "/index.html",
      "httpversion": "1.1",
      "response": "200",
      "bytes": "2326",
      "src_ip": "127.0.0.1",
      "__source": "test",
      "_parsed_time": "2024-12-25 10:00:15",
      "host": {
        "name": "logstash-container"
      }
    }
  ],
  "count": 1,
  "message": "æˆåŠŸè·å– 1 æ¡è§£æè®°å½•"
}
```

#### åŠŸèƒ½ç‰¹æ€§

- **æœ€æ–°è®°å½•**: è·å–æœ€å 50 æ¡è§£æè®°å½•
- **æ—¶é—´æˆ³**: æ¯æ¡è®°å½•åŒ…å« `_parsed_time` è§£ææ—¶é—´
- **å­—æ®µå®Œæ•´**: åŒ…å«æ‰€æœ‰ filter å¤„ç†åçš„å­—æ®µ
- **å®æ—¶æ›´æ–°**: æ”¯æŒè½®è¯¢è·å–æœ€æ–°æ•°æ®

---

### ğŸ“‹ 4. è·å– Logstash æ—¥å¿—æ¥å£

**ç«¯ç‚¹**: `/logstash_logs`  
**æ–¹æ³•**: `GET`  
**æè¿°**: è·å– Logstash è¿è¡Œæ—¥å¿—ï¼Œç”¨äºè°ƒè¯•å’Œé—®é¢˜æ’æŸ¥

#### è¯·æ±‚ç¤ºä¾‹

```bash
# è·å– Logstash æ—¥å¿—
curl http://localhost:19000/logstash_logs

# ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶
curl -s http://localhost:19000/logstash_logs | jq -r .logs > logstash.log

# æ£€æŸ¥é”™è¯¯ä¿¡æ¯
curl -s http://localhost:19000/logstash_logs | jq -r .logs | grep -i error

# å®æ—¶ç›‘æ§ï¼ˆæ¯5ç§’åˆ·æ–°ï¼‰
watch -n 5 'curl -s http://localhost:19000/logstash_logs | jq -r .logs | tail -20'
```

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "logs": "ğŸ“‹ Logstash å®¹å™¨æ—¥å¿— (Docker API)\nğŸ“… è·å–æ—¶é—´: 2024-12-25 10:00:15\nğŸ“Š æ˜¾ç¤ºæœ€è¿‘ 50 æ¡æ—¥å¿—\n================================================================================\n[2024-12-25T10:00:00,123][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}\n[2024-12-25T10:00:01,456][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=>\"8.14.2\"}\n[2024-12-25T10:00:02,789][INFO ][logstash.javapipeline    ][test] Pipeline started {\"pipeline.id\"=>\"test\"}\n[2024-12-25T10:00:03,012][INFO ][logstash.inputs.http     ][test] Starting http input listener {:address=>\"0.0.0.0:15515\"}\n[2024-12-25T10:00:05,345][INFO ][logstash.pipeline        ][test] Pipeline successfully reloaded"
}
```

#### æ—¥å¿—å†…å®¹è¯´æ˜

- **å¯åŠ¨ä¿¡æ¯**: Logstash æœåŠ¡å¯åŠ¨çŠ¶æ€
- **Pipeline çŠ¶æ€**: ç®¡é“åŠ è½½å’Œé‡è½½ä¿¡æ¯
- **é”™è¯¯ä¿¡æ¯**: é…ç½®è¯­æ³•é”™è¯¯å’Œè¿è¡Œå¼‚å¸¸
- **æ€§èƒ½ä¿¡æ¯**: å¤„ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨
- **ç½‘ç»œçŠ¶æ€**: HTTP è¾“å…¥ç«¯å£ç›‘å¬çŠ¶æ€

---

### ğŸ§ª 5. å‘é€æµ‹è¯•æ—¥å¿—æ¥å£

**ç«¯ç‚¹**: `/test`  
**æ–¹æ³•**: `POST`  
**æè¿°**: å‘é€æµ‹è¯•æ—¥å¿—åˆ° Logstash å¹¶è·å–è§£æç»“æœ

#### è¯·æ±‚å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…éœ€ | æè¿° |
|------|------|------|------|
| `logs` | string | æ˜¯ | è¦æµ‹è¯•çš„æ—¥å¿—å†…å®¹ |
| `is_json` | string | å¦ | æ˜¯å¦ä¸º JSON æ ¼å¼ (å€¼ä¸º "1" è¡¨ç¤ºæ˜¯) |

#### è¯·æ±‚ç¤ºä¾‹

```bash
# âœ… æ¨èæ–¹å¼ï¼šä½¿ç”¨ --data-urlencode é¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
curl -X POST http://localhost:19000/test \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "logs=127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326"

# âœ… å‘é€åŒ…å« + å·çš„æ—¥å¿—ï¼ˆæ—¶é—´æˆ³ã€URLç¼–ç ç­‰ï¼‰
curl -X POST http://localhost:19000/test \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "logs=<133>1 2025-09-10T12:08:07+08:00 SGPDRT-VSBRS01 BG 16703 - [meta sequenceId=\"46\"] session_data"

# âœ… å‘é€ JSON æ ¼å¼æ—¥å¿—
curl -X POST http://localhost:19000/test \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "logs={\"timestamp\": \"2023-12-25T10:00:00Z\", \"level\": \"info\", \"message\": \"ç”¨æˆ·ç™»å½•æˆåŠŸ\"}" \
  -d "is_json=1"

# âš ï¸ ä¸æ¨èï¼šä½¿ç”¨ -d å¯èƒ½å¯¼è‡´ + å·å˜ç©ºæ ¼
curl -X POST http://localhost:19000/test \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "logs=<133>1 2025-09-10T12:08:07+08:00 server BG 16703 - log_content"  # + ä¼šå˜æˆç©ºæ ¼

# ğŸ¯ å®Œæ•´æµ‹è¯•æµç¨‹ç¤ºä¾‹
# 1. ä¸Šä¼ é…ç½®
curl -X POST http://localhost:19000/upload_pipeline -F 'file=@bomgar.config'

# 2. æ¸…ç©ºç»“æœ
curl -X POST http://localhost:19000/clear_results

# 3. å‘é€æµ‹è¯•æ—¥å¿—
curl -X POST http://localhost:19000/test \
  -H "Content-Type: application/x-www-form-urlencoded" \
  --data-urlencode "logs=<133>1 2025-09-10T12:08:07+08:00 SGPDRT-VSBRS01 BG 16703 - [meta sequenceId=\"46\"] 1427:01:01:event=logout;site=remote.cit.seabank.com.sg;target=rep_client;when=1757477287;who=unknown;who_ip=116.12.204.154"

# 4. è·å–è§£æç»“æœ
curl -s http://localhost:19000/get_parsed_results | jq '.events[-1]'
```

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "message": "âœ… æ—¥å¿—å‘é€æˆåŠŸ",
  "events": [
    {
      "@timestamp": "2024-12-25T10:00:00.000Z",
      "message": "127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326",
      "clientip": "127.0.0.1",
      "verb": "GET",
      "request": "/index.html",
      "httpversion": "1.1",
      "response": "200",
      "bytes": "2326",
      "src_ip": "127.0.0.1"
    }
  ]
}
```

#### âš ï¸ é‡è¦æç¤º

| é—®é¢˜ç±»å‹ | ç°è±¡ | è§£å†³æ–¹æ¡ˆ |
|----------|------|----------|
| **æ—¶é—´æˆ³ä¸­çš„ `+` å·é—®é¢˜** | `2025-09-10T12:08:07+08:00` â†’ `2025-09-10T12:08:07 08:00` | ä½¿ç”¨ `--data-urlencode` æˆ–æ‰‹åŠ¨ç¼–ç ä¸º `%2B` |
| **ç‰¹æ®Šå­—ç¬¦ç¼–ç ** | `&`, `=`, `%` ç­‰è¢«é”™è¯¯è§£é‡Š | ä½¿ç”¨ `--data-urlencode` |
| **å¤šè¡Œæ—¥å¿—å¤„ç†** | æ¢è¡Œç¬¦ä¸¢å¤±æˆ–é”™è¯¯å¤„ç† | ä½¿ç”¨ `--data-urlencode` æˆ–æ–‡ä»¶ä¼ è¾“ |

---

### ğŸ—‘ï¸ 6. æ¸…ç©ºç»“æœæ¥å£

**ç«¯ç‚¹**: `/clear_results`  
**æ–¹æ³•**: `POST`  
**æè¿°**: æ¸…ç©ºè§£æç»“æœæ–‡ä»¶ï¼Œç”¨äºé‡æ–°å¼€å§‹æµ‹è¯•

#### è¯·æ±‚ç¤ºä¾‹

```bash
# æ¸…ç©ºè§£æç»“æœ
curl -X POST http://localhost:19000/clear_results

# æ¸…ç©ºå¹¶ç¡®è®¤
curl -X POST http://localhost:19000/clear_results && \
curl http://localhost:19000/get_parsed_results | jq .count
```

#### å“åº”ç¤ºä¾‹

```json
{
  "ok": true,
  "message": "ç»“æœå·²æ¸…ç©º"
}
```

---

### ğŸ“¡ API ä½¿ç”¨æœ€ä½³å®è·µ

#### ğŸ”„ **å®Œæ•´çš„æµ‹è¯•å·¥ä½œæµ**

```bash
#!/bin/bash
# Logstash è§„åˆ™æµ‹è¯•è„šæœ¬

BASE_URL="http://localhost:19000"

echo "ğŸ§¹ 1. æ¸…ç©ºå†å²ç»“æœ"
curl -s -X POST "$BASE_URL/clear_results" | jq .message

echo -e "\nğŸ”§ 2. æ›´æ–° Filter è§„åˆ™"
curl -s -X POST "$BASE_URL/save_filter" \
  -d "filter=grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } }" \
  | jq .message

echo -e "\nâ±ï¸ 3. ç­‰å¾…çƒ­é‡è½½å®Œæˆ"
sleep 3

echo -e "\nğŸ§ª 4. å‘é€æµ‹è¯•æ—¥å¿—"
curl -s -X POST "$BASE_URL/test" \
  -d "logs=127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] \"GET /index.html HTTP/1.1\" 200 2326" \
  | jq .message

echo -e "\nğŸ“Š 5. è·å–è§£æç»“æœ"
curl -s "$BASE_URL/get_parsed_results" | jq '.events[] | {client: .clientip, method: .verb, path: .request}'

echo -e "\nğŸ“‹ 6. æ£€æŸ¥ Logstash æ—¥å¿—"
curl -s "$BASE_URL/logstash_logs" | jq -r .logs | tail -5
```

#### ğŸ” **é”™è¯¯å¤„ç†ç¤ºä¾‹**

```bash
# æ£€æŸ¥ API å“åº”çŠ¶æ€
response=$(curl -s -X POST http://localhost:19000/save_filter -d "filter=invalid syntax")
status=$(echo "$response" | jq -r .ok)

if [ "$status" = "true" ]; then
  echo "âœ… Filter ä¿å­˜æˆåŠŸ"
else
  echo "âŒ Filter ä¿å­˜å¤±è´¥: $(echo "$response" | jq -r .message)"
fi

# æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
if curl -s http://localhost:19000/get_parsed_results > /dev/null; then
  echo "âœ… æœåŠ¡è¿è¡Œæ­£å¸¸"
else
  echo "âŒ æœåŠ¡ä¸å¯è®¿é—®ï¼Œè¯·æ£€æŸ¥å®¹å™¨çŠ¶æ€"
fi
```

#### ğŸ“ˆ **æ€§èƒ½ç›‘æ§è„šæœ¬**

```bash
#!/bin/bash
# ç›‘æ§ Logstash æ€§èƒ½

while true; do
  # è·å–å½“å‰è®°å½•æ•°
  count=$(curl -s http://localhost:19000/get_parsed_results | jq .count)
  
  # æ£€æŸ¥å†…å­˜ä½¿ç”¨
  memory=$(docker stats logstash-lab-logstash --no-stream --format "table {{.MemUsage}}" | tail -1)
  
  # æ£€æŸ¥é”™è¯¯æ—¥å¿—
  errors=$(curl -s http://localhost:19000/logstash_logs | jq -r .logs | grep -c ERROR || echo 0)
  
  echo "$(date): è®°å½•æ•°=$count, å†…å­˜=$memory, é”™è¯¯=$errors"
  sleep 10
done
```

### ğŸŒ å‰ç«¯ JavaScript é›†æˆ

```javascript
// Logstash API å®¢æˆ·ç«¯ç±»
class LogstashAPI {
  constructor(baseURL = 'http://localhost:19000') {
    this.baseURL = baseURL;
  }

  // ä¿å­˜ filter é…ç½®
  async saveFilter(filterContent) {
    const response = await fetch(`${this.baseURL}/save_filter`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
      body: `filter=${encodeURIComponent(filterContent)}`
    });
    return response.json();
  }

  // å‘é€æµ‹è¯•æ—¥å¿—
  async sendTestLog(logs, isJSON = false) {
    const body = `logs=${encodeURIComponent(logs)}${isJSON ? '&is_json=1' : ''}`;
    const response = await fetch(`${this.baseURL}/test`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
      body
    });
    return response.json();
  }

  // è·å–è§£æç»“æœ
  async getParsedResults() {
    const response = await fetch(`${this.baseURL}/get_parsed_results`);
    return response.json();
  }

  // è·å– Logstash æ—¥å¿—
  async getLogstashLogs() {
    const response = await fetch(`${this.baseURL}/logstash_logs`);
    return response.json();
  }

  // æ¸…ç©ºç»“æœ
  async clearResults() {
    const response = await fetch(`${this.baseURL}/clear_results`, { method: 'POST' });
    return response.json();
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const api = new LogstashAPI();

// ä¿å­˜ filter å¹¶æµ‹è¯•
async function testFilter() {
  try {
    // 1. ä¿å­˜ filter
    await api.saveFilter('grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }');
    
    // 2. ç­‰å¾…é‡è½½
    await new Promise(resolve => setTimeout(resolve, 3000));
    
    // 3. å‘é€æµ‹è¯•æ—¥å¿—
    const testResult = await api.sendTestLog('127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326');
    
    // 4. è·å–è§£æç»“æœ
    const results = await api.getParsedResults();
    
    console.log('è§£æç»“æœ:', results.events);
  } catch (error) {
    console.error('æµ‹è¯•å¤±è´¥:', error);
  }
}
```

### é€šç”¨å“åº”æ ¼å¼

æ‰€æœ‰ API ç«¯ç‚¹éƒ½è¿”å›ç»Ÿä¸€çš„ JSON æ ¼å¼ï¼š

```json
{
  "ok": true|false,
  "message": "æ“ä½œçŠ¶æ€æè¿°",
  "data": {...},       // å¯é€‰ï¼Œå…·ä½“æ•°æ®
  "events": [...],     // å¯é€‰ï¼Œäº‹ä»¶æ•°ç»„
  "count": 0,          // å¯é€‰ï¼Œè®°å½•æ•°é‡
  "logs": "..."        // å¯é€‰ï¼Œæ—¥å¿—å†…å®¹
}
```

## ğŸŒŠ MCP æœåŠ¡å™¨ä½¿ç”¨æŒ‡å—

### æ¦‚è¿°

MCP (Model Context Protocol) æœåŠ¡å™¨ä¸º AI å’Œè‡ªåŠ¨åŒ–å·¥å…·æä¾›äº†æ ‡å‡†åŒ–çš„ Logstash æµ‹è¯•æ¥å£ã€‚å®ƒæ”¯æŒï¼š
- ğŸš€ **æ–‡ä»¶ä¸Šä¼ **: ç›´æ¥ä¸Šä¼  Pipeline é…ç½®æ–‡ä»¶
- ğŸŒŠ **SSE æµå¼åé¦ˆ**: å®æ—¶ç›‘æ§æµ‹è¯•è¿›åº¦
- âš¡ **è‡ªåŠ¨åŒ–é›†æˆ**: æ ‡å‡† REST API æ¥å£
- ğŸ”„ **æ™ºèƒ½æ›¿æ¢**: è‡ªåŠ¨å¤„ç†æ¡ä»¶åˆ¤æ–­å’Œå…ƒæ•°æ®

### ğŸŒ æœåŠ¡åœ°å€

| æœåŠ¡ | åœ°å€ | è¯´æ˜ |
|------|------|------|
| **Web ç•Œé¢** | http://localhost:19000 | ä¸»è¦æµ‹è¯•ç•Œé¢ |
| **MCP æœåŠ¡å™¨** | http://localhost:19001 | AI è°ƒç”¨æ¥å£ |
| **SSE æµ‹è¯•é¡µé¢** | http://localhost:19001/test | å†…ç½®æµ‹è¯•ç•Œé¢ |
| **API æ–‡æ¡£** | http://localhost:19001/docs | å®Œæ•´ API æ–‡æ¡£ |

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### 1. ä½¿ç”¨å†…ç½®æµ‹è¯•é¡µé¢ï¼ˆæ¨èï¼‰

```bash
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ SSE æµ‹è¯•é¡µé¢
open http://localhost:19001/test
```

è¿™ä¸ªé¡µé¢æä¾›äº†å®Œæ•´çš„å¯è§†åŒ–æµ‹è¯•ç¯å¢ƒï¼ŒåŒ…æ‹¬ï¼š
- Pipeline é…ç½®ç¼–è¾‘å™¨
- æµ‹è¯•æ—¥å¿—è¾“å…¥æ¡†  
- å®æ—¶ SSE æµå¼åé¦ˆ
- æ­¥éª¤çº§è¿›åº¦è¿½è¸ª

#### 2. æ–‡ä»¶ä¸Šä¼ æ–¹å¼

```bash
# ä¸Šä¼  Pipeline é…ç½®æ–‡ä»¶
curl -X POST http://localhost:19001/tools/upload_pipeline \
  -F 'file=@your_pipeline.conf'

# å“åº”ç¤ºä¾‹
{
  "success": true,
  "message": "Pipeline å·²æˆåŠŸä¸Šä¼ å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒ",
  "extracted_filters": 1,
  "preview": "if \"test\" == [@metadata][type] { ... }"
}
```

#### 3. SSE æµå¼æµ‹è¯•

```bash
# ä½¿ç”¨ curl æµ‹è¯• SSE è¿æ¥ï¼ˆæ³¨æ„ -N å‚æ•°ä¿æŒè¿æ¥ï¼‰
curl -N "http://localhost:19001/sse/test_pipeline_complete?pipeline_content=filter{grok{match=>{\"message\"=>\"%{GREEDYDATA:content\"}}}&test_logs=[\"test log message\"]"
```

### ğŸ”§ å¸¸è§é…ç½®é”™è¯¯

#### âŒ é”™è¯¯çš„ SSE é…ç½®

```bash
# é”™è¯¯ï¼šç¼ºå°‘å…·ä½“ç«¯ç‚¹
@http://192.168.31.218:19001/sse
```

#### âœ… æ­£ç¡®çš„é…ç½®

```bash
# æ­£ç¡®ï¼šSSE æµå¼æµ‹è¯•ç«¯ç‚¹
http://192.168.31.218:19001/sse/test_pipeline_complete

# æˆ–è€…ä½¿ç”¨æµ‹è¯•é¡µé¢
http://192.168.31.218:19001/test
```

### ğŸ› ï¸ æ•…éšœæ’é™¤

#### Docker æ„å»ºç¼“å­˜é—®é¢˜

å¦‚æœä¿®æ”¹ä»£ç åå®¹å™¨æ²¡æœ‰æ›´æ–°ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¸…ç†ç¼“å­˜ï¼š

```bash
# æ¸…ç† Docker ç¼“å­˜
sudo docker system prune -f

# å¼ºåˆ¶é‡æ–°æ„å»º
sudo docker compose build --no-cache mcp-server

# é‡å¯æœåŠ¡
sudo docker compose restart mcp-server
```

#### æœåŠ¡å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥ MCP æœåŠ¡å™¨çŠ¶æ€
curl http://localhost:19001/tools/health_check

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
sudo docker compose ps

# æŸ¥çœ‹ MCP æœåŠ¡å™¨æ—¥å¿—
sudo docker compose logs -f mcp-server
```

#### ç½‘ç»œè¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥ç«¯å£æ˜¯å¦æ­£åœ¨ç›‘å¬
sudo netstat -tlnp | grep 19001

# æ£€æŸ¥å®¹å™¨ç½‘ç»œ
sudo docker network ls
sudo docker network inspect logstash-lab_default
```

### ğŸ“‹ MCP å·¥å…·åˆ—è¡¨

| å·¥å…·åç§° | åŠŸèƒ½æè¿° | è¾“å…¥æ ¼å¼ |
|----------|----------|----------|
| `upload_pipeline` | ä¸Šä¼  Pipeline é…ç½® | æ–‡ä»¶/è¡¨å•/JSON |
| `send_test_log` | å‘é€æµ‹è¯•æ—¥å¿— | JSON |
| `get_parsed_results` | è·å–è§£æç»“æœ | GET |
| `clear_results` | æ¸…ç©ºæµ‹è¯•ç»“æœ | POST |
| `get_logstash_logs` | è·å– Logstash æ—¥å¿— | GET |
| `health_check` | å¥åº·çŠ¶æ€æ£€æŸ¥ | GET |
| `test_pipeline_complete_stream` | SSE æµå¼å®Œæ•´æµ‹è¯• | SSE |

### ğŸ¯ AI é›†æˆç¤ºä¾‹

```python
import requests
import json

# ä¸Šä¼  Pipeline é…ç½®
def upload_pipeline(config_file):
    with open(config_file, 'rb') as f:
        response = requests.post(
            'http://localhost:19001/tools/upload_pipeline',
            files={'file': f}
        )
    return response.json()

# å‘é€æµ‹è¯•æ—¥å¿—
def test_log(log_content):
    response = requests.post(
        'http://localhost:19001/tools/send_test_log',
        json={'log_content': log_content}
    )
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
result = upload_pipeline('bomgar.conf')
if result['success']:
    test_result = test_log('test log message')
    print(f"è§£æç»“æœ: {test_result['latest_event']}")
```

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒï¼š[MCP æœåŠ¡å™¨å®Œæ•´æ–‡æ¡£](mcp_server/README.md)

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### æœåŠ¡ç®¡ç†
```bash
# å¯åŠ¨æœåŠ¡
sudo docker compose up -d --build

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€  
sudo docker compose ps

# é‡å¯ç‰¹å®šæœåŠ¡
sudo docker compose restart web
sudo docker compose restart logstash

# åœæ­¢æ‰€æœ‰æœåŠ¡
sudo docker compose down
```

### æ—¥å¿—æŸ¥çœ‹
```bash
# å®æ—¶æŸ¥çœ‹æ‰€æœ‰æ—¥å¿—
sudo docker compose logs -f

# æŸ¥çœ‹ Logstash æ—¥å¿—ï¼ˆæœ€è¿‘50æ¡ï¼‰
sudo docker compose logs --tail=50 logstash

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
sudo docker compose logs logstash | grep -i error

# ç›‘æ§è§£æç»“æœ
tail -f data/out/events.ndjson | jq .
```

### å¼€å‘è°ƒè¯•
```bash
# è¿›å…¥å®¹å™¨è°ƒè¯•
sudo docker exec -it logstash-lab-web bash
sudo docker exec -it logstash-lab-logstash bash

# æ£€æŸ¥é…ç½®è¯­æ³•
sudo docker exec logstash-lab-logstash bin/logstash --config.test_and_exit

# é‡æ–°æ„å»ºé•œåƒ
sudo docker compose build --no-cache
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

<details>
<summary><b>ğŸ“Œ Web ç•Œé¢æ— æ³•è®¿é—®</b></summary>

**å¯èƒ½åŸå› ï¼š**
- ç«¯å£è¢«å ç”¨
- å®¹å™¨å¯åŠ¨å¤±è´¥
- é˜²ç«å¢™é˜»æ­¢

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# 1. æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :19000

# 2. æŸ¥çœ‹å®¹å™¨çŠ¶æ€
sudo docker compose ps

# 3. æŸ¥çœ‹å®¹å™¨æ—¥å¿—
sudo docker compose logs web

# 4. é‡æ–°æ„å»º
sudo docker compose build --no-cache web
sudo docker compose up -d
```
</details>

<details>
<summary><b>ğŸ“Œ Logstash å¯åŠ¨å¤±è´¥</b></summary>

**å¯èƒ½åŸå› ï¼š**
- å†…å­˜ä¸è¶³
- é…ç½®è¯­æ³•é”™è¯¯
- ç«¯å£å†²çª

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# 1. æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h

# 2. éªŒè¯é…ç½®è¯­æ³•  
sudo docker exec logstash-lab-logstash bin/logstash --config.test_and_exit

# 3. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
sudo docker compose logs --tail=100 logstash

# 4. è°ƒæ•´å†…å­˜é™åˆ¶
# ç¼–è¾‘ docker-compose.yml ä¸­çš„ LS_JAVA_OPTS
```
</details>

<details>
<summary><b>ğŸ“Œ Filter è§„åˆ™ä¸ç”Ÿæ•ˆ</b></summary>

**å¯èƒ½åŸå› ï¼š**
- è¯­æ³•é”™è¯¯
- æ¡ä»¶åˆ¤æ–­ä¸åŒ¹é…
- çƒ­é‡è½½æœªå®Œæˆ

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# 1. æ£€æŸ¥è¯­æ³•é”™è¯¯
sudo docker compose logs --tail=20 logstash | grep -i error

# 2. ç­‰å¾…çƒ­é‡è½½å®Œæˆï¼ˆ3-5ç§’ï¼‰

# 3. æ‰‹åŠ¨é‡å¯ Logstash
sudo docker compose restart logstash

# 4. ä½¿ç”¨ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ¡ä»¶åˆ¤æ–­
# è¾“å…¥ä»»ä½•æ¡ä»¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ›¿æ¢ä¸º "test"
```
</details>

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å†…å­˜é…ç½®**ï¼šæ ¹æ®æ—¥å¿—é‡è°ƒæ•´ Logstash å†…å­˜
2. **ç£ç›˜ç©ºé—´**ï¼šå®šæœŸæ¸…ç† `data/out/events.ndjson`
3. **ç½‘ç»œé…ç½®**ï¼šç¡®ä¿å®¹å™¨é—´ç½‘ç»œé€šä¿¡æ­£å¸¸
4. **è§„åˆ™ä¼˜åŒ–**ï¼šé¿å…è¿‡äºå¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼

## ğŸ” å®‰å…¨æ³¨æ„äº‹é¡¹

- âš ï¸ **ä»…é™æµ‹è¯•ç¯å¢ƒä½¿ç”¨**ï¼Œä¸è¦åœ¨ç”Ÿäº§ç¯å¢ƒæš´éœ²ç«¯å£
- ğŸ›¡ï¸ **ä¸è¦å¤„ç†æ•æ„Ÿæ•°æ®**ï¼Œæœ¬å·¥å…·ç”¨äºè§„åˆ™æµ‹è¯•
- ğŸ”’ **ç½‘ç»œéš”ç¦»**ï¼Œå»ºè®®åœ¨å†…ç½‘ç¯å¢ƒä½¿ç”¨
- ğŸ” **å®šæœŸæ›´æ–°**ï¼Œä¿æŒ Docker é•œåƒä¸ºæœ€æ–°ç‰ˆæœ¬

## ğŸ“Š ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|----------|----------|
| **CPU** | 1 æ ¸å¿ƒ | 2+ æ ¸å¿ƒ |
| **å†…å­˜** | 1GB | 2GB+ |
| **ç£ç›˜** | 2GB | 5GB+ |
| **ç½‘ç»œ** | 1Mbps | 10Mbps+ |

## ğŸ¯ ä½¿ç”¨æŠ€å·§

### ğŸ’¡ **Filter è§„åˆ™ç¼–å†™æŠ€å·§**

1. **ä»ç®€å•å¼€å§‹**ï¼šå…ˆç”¨åŸºæœ¬çš„ grok æ¨¡å¼æµ‹è¯•
2. **é€æ­¥æ·»åŠ **ï¼šç¡®è®¤åŸºç¡€è§„åˆ™å·¥ä½œåå†æ·»åŠ å¤æ‚é€»è¾‘
3. **ä½¿ç”¨æ¡ä»¶åˆ¤æ–­**ï¼šæé«˜å¤„ç†æ•ˆç‡
4. **å–„ç”¨ç¤ºä¾‹æ¨¡æ¿**ï¼šåŸºäºå†…ç½®æ¨¡æ¿ä¿®æ”¹æ›´é«˜æ•ˆ

### ğŸ” **è°ƒè¯•æŠ€å·§**

1. **æŸ¥çœ‹åŸå§‹è¾“å‡º**ï¼šä½¿ç”¨ stdout è¾“å‡ºæŸ¥çœ‹ä¸­é—´ç»“æœ
2. **åˆ†æ­¥æµ‹è¯•**ï¼šå°†å¤æ‚è§„åˆ™æ‹†åˆ†ä¸ºå¤šä¸ªæ­¥éª¤æµ‹è¯•
3. **ä½¿ç”¨ Logstash æ—¥å¿—**ï¼šåŠæ—¶æŸ¥çœ‹é”™è¯¯ä¿¡æ¯
4. **JSON æ¨¡å¼æµ‹è¯•**ï¼šå¯¹äºç»“æ„åŒ–æ•°æ®ä½¿ç”¨ JSON è¾“å…¥æ¨¡å¼

### âš¡ **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**

1. **é¿å…è¿‡åº¦è§£æ**ï¼šåªè§£æéœ€è¦çš„å­—æ®µ
2. **åˆç†ä½¿ç”¨æ¡ä»¶**ï¼šå‡å°‘ä¸å¿…è¦çš„å¤„ç†
3. **å®šæœŸæ¸…ç†æ•°æ®**ï¼šé¿å…è¾“å‡ºæ–‡ä»¶è¿‡å¤§
4. **å†…å­˜ç›‘æ§**ï¼šå…³æ³¨ Logstash å†…å­˜ä½¿ç”¨

## ğŸ“š å­¦ä¹ èµ„æº

- ğŸ“– [Logstash å®˜æ–¹æ–‡æ¡£](https://www.elastic.co/guide/en/logstash/current/index.html)
- ğŸ” [Grok æ¨¡å¼åº“](https://github.com/elastic/logstash/blob/v1.4.2/patterns/grok-patterns)
- ğŸ”§ [Filter æ’ä»¶æ–‡æ¡£](https://www.elastic.co/guide/en/logstash/current/filter-plugins.html)
- ğŸ [Flask å¿«é€Ÿå…¥é—¨](https://flask.palletsprojects.com/quickstart/)
- ğŸ³ [Docker Compose æŒ‡å—](https://docs.docker.com/compose/)

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ™ è‡´è°¢

- [Elastic](https://www.elastic.co/) - æä¾›å¼ºå¤§çš„ Logstash å¼•æ“
- [Flask](https://flask.palletsprojects.com/) - ç®€æ´çš„ Python Web æ¡†æ¶
- [Docker](https://www.docker.com/) - å®¹å™¨åŒ–æŠ€æœ¯æ”¯æŒ

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **[AI é›†æˆæŒ‡å—](AI_INTEGRATION_GUIDE.md)**: ä¸ºç¬¬ä¸‰æ–¹ AI æä¾›å®Œæ•´çš„è°ƒç”¨æŒ‡å—
- **[MCP æœåŠ¡å™¨æ–‡æ¡£](mcp_server/README.md)**: SSE æµå¼ MCP æœåŠ¡å™¨ä½¿ç”¨æŒ‡å—

---

<div align="center">

**ğŸ‰ å¼€å§‹ä½ çš„ Logstash è§„åˆ™æµ‹è¯•ä¹‹æ—…ï¼**

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™å®ƒä¸€ä¸ª â­ï¸

[æŠ¥å‘Šé—®é¢˜](https://github.com/username/logstash-lab/issues) â€¢ [åŠŸèƒ½å»ºè®®](https://github.com/username/logstash-lab/issues) â€¢ [åŠ å…¥è®¨è®º](https://github.com/username/logstash-lab/discussions)

</div>