#!/usr/bin/env python3
"""
Logstash æµ‹è¯•æœåŠ¡ SSE ç‰ˆæœ¬ MCP æœåŠ¡å™¨
æä¾› Server-Sent Events æµå¼å“åº”ï¼Œæ”¯æŒå®æ—¶è¿›åº¦åé¦ˆ
"""

import asyncio
import json
import tempfile
import os
import traceback
import time
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional, Union, Generator
from flask import Flask, request, jsonify, Response, stream_template
from flask_cors import CORS
import requests
import threading

# Logstash æµ‹è¯•æœåŠ¡é…ç½®
LOGSTASH_SERVICE_URL = os.getenv("LOGSTASH_SERVICE_URL", "http://web:19000")

app = Flask(__name__)
CORS(app)  # å¯ç”¨è·¨åŸŸæ”¯æŒ

class LogstashMCPServer:
    """Logstash æµ‹è¯•æœåŠ¡ SSE ç‰ˆæœ¬ MCP æœåŠ¡å™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/x-www-form-urlencoded'
        })
        # æœåŠ¡å™¨å¯åŠ¨æ—¶é—´
        self.start_time = datetime.now()
        # æ´»è·ƒçš„ SSE è¿æ¥
        self.active_connections = {}
        
    def _make_request(self, method: str, endpoint: str, data: Optional[Dict] = None, files: Optional[Dict] = None, timeout: int = 30) -> Dict[str, Any]:
        """ç»Ÿä¸€çš„è¯·æ±‚å¤„ç†æ–¹æ³•"""
        url = f"{LOGSTASH_SERVICE_URL}{endpoint}"
        
        try:
            if method.upper() == "GET":
                response = requests.get(url, timeout=timeout)
            elif method.upper() == "POST":
                if files:
                    response = requests.post(url, files=files, timeout=timeout)
                else:
                    response = self.session.post(url, data=data, timeout=timeout)
            else:
                return {"success": False, "error": f"ä¸æ”¯æŒçš„ HTTP æ–¹æ³•: {method}"}
            
            if response.status_code == 200:
                return response.json()
            else:
                return {
                    "success": False, 
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "status_code": response.status_code
                }
        except requests.exceptions.ConnectionError:
            return {"success": False, "error": "æ— æ³•è¿æ¥åˆ° Logstash æµ‹è¯•æœåŠ¡"}
        except requests.exceptions.Timeout:
            return {"success": False, "error": f"è¯·æ±‚è¶…æ—¶ ({timeout}s)"}
        except Exception as e:
            return {"success": False, "error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"}
    
    def _send_sse_event(self, connection_id: str, event_type: str, data: Dict[str, Any]):
        """å‘é€ SSE äº‹ä»¶"""
        if connection_id in self.active_connections:
            event_data = {
                "type": event_type,
                "timestamp": datetime.now().isoformat(),
                "data": data
            }
            try:
                # è¿™é‡Œå®é™…çš„ SSE å‘é€ä¼šåœ¨è·¯ç”±ä¸­å¤„ç†
                # è¿™ä¸ªæ–¹æ³•ä¸»è¦ç”¨äºæ•°æ®å‡†å¤‡
                return event_data
            except Exception as e:
                print(f"SSE å‘é€å¤±è´¥: {e}")
        return None
    
    def upload_pipeline(self, pipeline_content: str, use_file_upload: bool = True) -> Dict[str, Any]:
        """ä¸Šä¼  Pipeline é…ç½®"""
        if use_file_upload:
            # æ–‡ä»¶ä¸Šä¼ æ–¹å¼ï¼ˆæ¨èï¼‰
            with tempfile.NamedTemporaryFile(mode='w', suffix='.conf', delete=False) as f:
                f.write(pipeline_content)
                temp_file = f.name
            
            try:
                with open(temp_file, 'rb') as f:
                    files = {'file': ('pipeline.conf', f, 'text/plain')}
                    result = self._make_request("POST", "/upload_pipeline", files=files)
            finally:
                os.unlink(temp_file)
        else:
            # æ–‡æœ¬å†…å®¹ä¸Šä¼ 
            data = {"pipeline": pipeline_content}
            result = self._make_request("POST", "/upload_pipeline", data=data)
        
        return {
            "success": result.get("ok", False),
            "message": result.get("message", ""),
            "extracted_filters": result.get("extracted_filters", 0),
            "preview": result.get("applied_filter_preview", "")[:200] + "..." if result.get("applied_filter_preview") else "",
            "raw_response": result
        }
    
    def send_test_log(self, log_content: str, is_json: bool = False) -> Dict[str, Any]:
        """å‘é€æµ‹è¯•æ—¥å¿—"""
        data = {"logs": log_content}
        if is_json:
            data["is_json"] = "1"
        
        result = self._make_request("POST", "/test", data=data)
        events = result.get("events", [])
        
        return {
            "success": result.get("ok", False),
            "message": result.get("message", ""),
            "events_count": len(events),
            "events": events,
            "latest_event": events[-1] if events else None,
            "raw_response": result
        }
    
    def get_parsed_results(self, count: int = -1) -> Dict[str, Any]:
        """è·å–è§£æç»“æœ"""
        result = self._make_request("GET", "/get_parsed_results")
        events = result.get("events", [])
        
        if count > 0:
            events = events[-count:]
        
        return {
            "success": result.get("ok", False),
            "total_count": result.get("count", 0),
            "returned_count": len(events),
            "events": events,
            "latest_event": events[-1] if events else None,
            "raw_response": result
        }
    
    def clear_results(self) -> Dict[str, Any]:
        """æ¸…ç©ºè§£æç»“æœ"""
        result = self._make_request("POST", "/clear_results")
        
        return {
            "success": result.get("ok", False),
            "message": result.get("message", ""),
            "raw_response": result
        }
    
    def get_logstash_logs(self, filter_errors: bool = False) -> Dict[str, Any]:
        """è·å– Logstash æ—¥å¿—"""
        result = self._make_request("GET", "/logstash_logs")
        logs = result.get("logs", "")
        
        if filter_errors:
            log_lines = logs.split('\n')
            error_lines = [line for line in log_lines if 'ERROR' in line.upper()]
            filtered_logs = '\n'.join(error_lines)
            
            return {
                "success": result.get("ok", False),
                "total_lines": len(log_lines),
                "error_lines": len(error_lines),
                "logs": filtered_logs,
                "raw_response": result
            }
        
        return {
            "success": result.get("ok", False),
            "logs": logs,
            "raw_response": result
        }
    
    def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        result = self._make_request("GET", "/get_parsed_results", timeout=5)
        healthy = result.get("ok", False) and not result.get("error")
        
        return {
            "healthy": healthy,
            "logstash_service_url": LOGSTASH_SERVICE_URL,
            "server_start_time": self.start_time.isoformat(),
            "current_time": datetime.now().isoformat(),
            "details": result
        }
    
    def test_pipeline_complete_stream(self, pipeline_content: str, test_logs: List[str], 
                                    is_json: bool = False, wait_time: int = 3) -> Generator[str, None, None]:
        """å®Œæ•´çš„ Pipeline æµ‹è¯•æµç¨‹ - SSE æµå¼ç‰ˆæœ¬"""
        connection_id = str(uuid.uuid4())
        self.active_connections[connection_id] = True
        
        def send_event(event_type: str, data: Dict[str, Any]):
            event_json = json.dumps({
                "type": event_type,
                "timestamp": datetime.now().isoformat(),
                "data": data
            }, ensure_ascii=False)
            return f"data: {event_json}\n\n"
        
        try:
            yield send_event("start", {
                "message": "å¼€å§‹ Pipeline æµ‹è¯•æµç¨‹",
                "pipeline_preview": pipeline_content[:100] + "..." if len(pipeline_content) > 100 else pipeline_content,
                "test_logs_count": len(test_logs)
            })
            
            # 1. å¥åº·æ£€æŸ¥
            yield send_event("progress", {"step": "health_check", "message": "æ­£åœ¨æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€..."})
            health_result = self.health_check()
            if not health_result["healthy"]:
                yield send_event("error", {"step": "health_check", "message": "Logstash æµ‹è¯•æœåŠ¡ä¸å¯ç”¨", "details": health_result})
                return
            yield send_event("success", {"step": "health_check", "message": "âœ… æœåŠ¡å¯ç”¨"})
            
            # 2. æ¸…ç©ºå†å²ç»“æœ
            yield send_event("progress", {"step": "clear_results", "message": "æ­£åœ¨æ¸…ç©ºå†å²ç»“æœ..."})
            clear_result = self.clear_results()
            yield send_event("success", {"step": "clear_results", "message": clear_result.get("message", "æ¸…ç©ºå®Œæˆ")})
            
            # 3. ä¸Šä¼  Pipeline
            yield send_event("progress", {"step": "upload_pipeline", "message": "æ­£åœ¨ä¸Šä¼  Pipeline é…ç½®..."})
            upload_result = self.upload_pipeline(pipeline_content, use_file_upload=True)
            if not upload_result["success"]:
                yield send_event("error", {
                    "step": "upload_pipeline", 
                    "message": f"Pipeline ä¸Šä¼ å¤±è´¥: {upload_result.get('message')}", 
                    "details": upload_result
                })
                return
            yield send_event("success", {
                "step": "upload_pipeline", 
                "message": upload_result.get("message"),
                "extracted_filters": upload_result.get("extracted_filters"),
                "preview": upload_result.get("preview")
            })
            
            # 4. ç­‰å¾…çƒ­é‡è½½
            yield send_event("progress", {"step": "wait_reload", "message": f"ç­‰å¾… {wait_time} ç§’çƒ­é‡è½½..."})
            for i in range(wait_time):
                time.sleep(1)
                yield send_event("progress", {
                    "step": "wait_reload", 
                    "message": f"çƒ­é‡è½½ä¸­... {i+1}/{wait_time}s",
                    "progress": (i+1) / wait_time * 100
                })
            yield send_event("success", {"step": "wait_reload", "message": f"çƒ­é‡è½½å®Œæˆ"})
            
            # 5. å‘é€æµ‹è¯•æ—¥å¿—
            all_events = []
            for i, log in enumerate(test_logs):
                yield send_event("progress", {
                    "step": f"send_log_{i+1}", 
                    "message": f"æ­£åœ¨å‘é€ç¬¬ {i+1}/{len(test_logs)} æ¡æ—¥å¿—...",
                    "log_preview": log[:50] + "..." if len(log) > 50 else log
                })
                
                send_result = self.send_test_log(log, is_json)
                
                if send_result["success"]:
                    yield send_event("success", {
                        "step": f"send_log_{i+1}", 
                        "message": send_result.get("message"),
                        "events_count": send_result.get("events_count", 0),
                        "latest_event": send_result.get("latest_event")
                    })
                    all_events.extend(send_result.get("events", []))
                else:
                    yield send_event("error", {
                        "step": f"send_log_{i+1}", 
                        "message": f"æ—¥å¿— {i+1} å‘é€å¤±è´¥: {send_result.get('message')}", 
                        "details": send_result
                    })
            
            # 6. è·å–æœ€ç»ˆè§£æç»“æœ
            yield send_event("progress", {"step": "get_results", "message": "æ­£åœ¨è·å–æœ€ç»ˆè§£æç»“æœ..."})
            parsed_result = self.get_parsed_results()
            if parsed_result["success"]:
                yield send_event("success", {
                    "step": "get_results", 
                    "message": f"è·å–åˆ° {len(parsed_result.get('events', []))} æ¡è§£æè®°å½•",
                    "total_count": parsed_result.get("total_count"),
                    "events": parsed_result.get("events", [])
                })
            else:
                yield send_event("error", {
                    "step": "get_results", 
                    "message": f"è·å–ç»“æœå¤±è´¥: {parsed_result.get('message')}", 
                    "details": parsed_result
                })
            
            # 7. æ£€æŸ¥é”™è¯¯æ—¥å¿—
            yield send_event("progress", {"step": "check_logs", "message": "æ­£åœ¨æ£€æŸ¥ Logstash é”™è¯¯æ—¥å¿—..."})
            logs_result = self.get_logstash_logs(filter_errors=True)
            if logs_result["success"]:
                error_count = logs_result.get("error_lines", 0)
                if error_count > 0:
                    yield send_event("warning", {
                        "step": "check_logs", 
                        "message": f"å‘ç° {error_count} ä¸ª Logstash é”™è¯¯",
                        "error_logs": logs_result.get("logs", "")
                    })
                else:
                    yield send_event("success", {"step": "check_logs", "message": "æœªå‘ç°é”™è¯¯"})
            
            # 8. å®Œæˆ
            yield send_event("complete", {
                "message": "Pipeline æµ‹è¯•æµç¨‹å®Œæˆ",
                "total_events": len(parsed_result.get("events", [])),
                "success": True
            })
            
        except Exception as e:
            yield send_event("error", {
                "step": "exception", 
                "message": f"æ‰§è¡Œå¼‚å¸¸: {str(e)}", 
                "traceback": traceback.format_exc()
            })
        finally:
            # æ¸…ç†è¿æ¥
            if connection_id in self.active_connections:
                del self.active_connections[connection_id]
    
    def get_test_guidance(self, user_request: str, pipeline_content: str = "", test_logs: List[str] = None) -> str:
        """æ™ºèƒ½æµ‹è¯•æŒ‡å¯¼ - æ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨åˆ†æå¹¶æä¾›æµ‹è¯•å»ºè®®å’Œæ­¥éª¤é¡ºåº"""
        if test_logs is None:
            test_logs = []
        
        guidance = []
        guidance.append("ğŸ¯ **æ™ºèƒ½æµ‹è¯•æŒ‡å¯¼**\n")
        
        # åˆ†æç”¨æˆ·è¯·æ±‚
        request_lower = user_request.lower()
        
        # 1. åœºæ™¯è¯†åˆ«
        guidance.append("## ğŸ“‹ **æµ‹è¯•åœºæ™¯åˆ†æ**")
        
        if any(keyword in request_lower for keyword in ['æ–°å»º', 'åˆ›å»º', 'å¼€å‘', 'ä»é›¶', 'new']):
            scenario = "æ–°å»ºé…ç½®"
            guidance.append("âœ… **åœºæ™¯**: æ–°å»º Pipeline é…ç½®å¼€å‘")
        elif any(keyword in request_lower for keyword in ['è°ƒè¯•', 'debug', 'é”™è¯¯', 'é—®é¢˜', 'å¤±è´¥', 'ä¸å·¥ä½œ']):
            scenario = "è°ƒè¯•ä¿®å¤"
            guidance.append("âœ… **åœºæ™¯**: è°ƒè¯•ç°æœ‰é…ç½®é—®é¢˜")
        elif any(keyword in request_lower for keyword in ['æµ‹è¯•', 'test', 'éªŒè¯', 'æ£€æŸ¥']):
            scenario = "æµ‹è¯•éªŒè¯"
            guidance.append("âœ… **åœºæ™¯**: æµ‹è¯•éªŒè¯é…ç½®åŠŸèƒ½")
        elif any(keyword in request_lower for keyword in ['ä¼˜åŒ–', 'æ€§èƒ½', 'æ”¹è¿›', 'æå‡']):
            scenario = "æ€§èƒ½ä¼˜åŒ–"
            guidance.append("âœ… **åœºæ™¯**: æ€§èƒ½ä¼˜åŒ–å’Œæ”¹è¿›")
        else:
            scenario = "é€šç”¨æµ‹è¯•"
            guidance.append("âœ… **åœºæ™¯**: é€šç”¨æµ‹è¯•æµç¨‹")
        
        # 2. æ¨èæµ‹è¯•æ­¥éª¤
        guidance.append("\n## ğŸš€ **æ¨èæµ‹è¯•æ­¥éª¤**")
        
        if scenario == "æ–°å»ºé…ç½®":
            steps = [
                "1. **å¥åº·æ£€æŸ¥** - ç¡®ä¿æœåŠ¡æ­£å¸¸è¿è¡Œ",
                "2. **ä¸Šä¼ é…ç½®** - ä½¿ç”¨ `upload_pipeline` ä¸Šä¼ æ‚¨çš„æ–°é…ç½®",
                "3. **å‘é€æ ·æœ¬æ—¥å¿—** - ä½¿ç”¨ `send_test_log` å‘é€æµ‹è¯•æ•°æ®",
                "4. **æ£€æŸ¥è§£æç»“æœ** - ä½¿ç”¨ `get_parsed_results` æŸ¥çœ‹è¾“å‡º",
                "5. **è°ƒè¯•é”™è¯¯æ—¥å¿—** - å¦‚æœ‰é—®é¢˜ï¼Œä½¿ç”¨ `get_logstash_logs` æŸ¥çœ‹é”™è¯¯",
                "6. **è¿­ä»£ä¼˜åŒ–** - æ ¹æ®ç»“æœè°ƒæ•´é…ç½®å¹¶é‡å¤æµ‹è¯•"
            ]
        elif scenario == "è°ƒè¯•ä¿®å¤":
            steps = [
                "1. **è·å–é”™è¯¯æ—¥å¿—** - ä½¿ç”¨ `get_logstash_logs` æŸ¥çœ‹å…·ä½“é”™è¯¯ä¿¡æ¯",
                "2. **æ¸…ç©ºå†å²ç»“æœ** - ä½¿ç”¨ `clear_results` æ¸…ç†æ—§æ•°æ®",
                "3. **é‡æ–°ä¸Šä¼ é…ç½®** - ä½¿ç”¨ `upload_pipeline` ä¸Šä¼ ä¿®å¤åçš„é…ç½®",
                "4. **é‡ç°é—®é¢˜** - ä½¿ç”¨ `send_test_log` å‘é€å¯¼è‡´é—®é¢˜çš„æ—¥å¿—",
                "5. **åˆ†æç»“æœ** - ä½¿ç”¨ `get_parsed_results` æ£€æŸ¥æ˜¯å¦ä¿®å¤",
                "6. **å¥åº·æ£€æŸ¥** - ç¡®è®¤æœåŠ¡çŠ¶æ€æ­£å¸¸"
            ]
        elif scenario == "æµ‹è¯•éªŒè¯":
            steps = [
                "1. **å¥åº·æ£€æŸ¥** - ä½¿ç”¨ `health_check` ç¡®è®¤æœåŠ¡çŠ¶æ€",
                "2. **æ‰¹é‡æµ‹è¯•** - ä½¿ç”¨ `test_pipeline_complete_stream` è¿›è¡Œå®Œæ•´æµç¨‹æµ‹è¯•",
                "3. **éªŒè¯è¾¹ç•Œæƒ…å†µ** - æµ‹è¯•å¼‚å¸¸æ—¥å¿—æ ¼å¼å’Œç‰¹æ®Šå­—ç¬¦",
                "4. **æ€§èƒ½éªŒè¯** - æµ‹è¯•å¤§é‡æ—¥å¿—çš„å¤„ç†èƒ½åŠ›",
                "5. **ç»“æœå¯¹æ¯”** - å¯¹æ¯”æœŸæœ›è¾“å‡ºå’Œå®é™…è¾“å‡º"
            ]
        else:
            steps = [
                "1. **å¥åº·æ£€æŸ¥** - ä½¿ç”¨ `health_check` ç¡®è®¤æœåŠ¡çŠ¶æ€",
                "2. **ä¸Šä¼ é…ç½®** - ä½¿ç”¨ `upload_pipeline` æ›´æ–°é…ç½®",
                "3. **å‘é€æµ‹è¯•æ—¥å¿—** - ä½¿ç”¨ `send_test_log` æµ‹è¯•è§£æ",
                "4. **è·å–ç»“æœ** - ä½¿ç”¨ `get_parsed_results` æŸ¥çœ‹è¾“å‡º",
                "5. **æ£€æŸ¥æ—¥å¿—** - å¦‚æœ‰é—®é¢˜ä½¿ç”¨ `get_logstash_logs` è°ƒè¯•"
            ]
        
        for step in steps:
            guidance.append(f"   {step}")
        
        # 3. é‡è¦æç¤º
        guidance.append("\n## âš¡ **é‡è¦æç¤º - è‡ªåŠ¨åŒ–ç‰¹æ€§**")
        guidance.append("ğŸ”„ **æ¡ä»¶åˆ¤æ–­è‡ªåŠ¨æ›¿æ¢**: ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç† `if` æ¡ä»¶åˆ¤æ–­")
        guidance.append("â€¢ æ— è®ºæ‚¨è¾“å…¥ `if \"xxx\" == [@metadata][type]` ä¸­çš„ä»»ä½•å€¼")
        guidance.append("â€¢ ç³»ç»Ÿéƒ½ä¼šè‡ªåŠ¨æ›¿æ¢ä¸º `if \"test\" == [@metadata][type]`")
        guidance.append("â€¢ åŒæ—¶è‡ªåŠ¨è®¾ç½® `[@metadata][type] = \"test\"`")
        guidance.append("â€¢ **æ‚¨æ— éœ€æ‹…å¿ƒæ¡ä»¶åŒ¹é…é—®é¢˜ï¼Œä¸“æ³¨ç¼–å†™ filter é€»è¾‘å³å¯**")
        
        # 4. å…·ä½“å»ºè®®
        guidance.append("\n## ğŸ’¡ **å…·ä½“å»ºè®®**")
        
        if pipeline_content:
            guidance.append("**é…ç½®åˆ†æ**:")
            if "grok" in pipeline_content.lower():
                guidance.append("â€¢ æ£€æµ‹åˆ° Grok æ¨¡å¼ï¼Œå»ºè®®å…ˆæµ‹è¯•ç®€å•æ—¥å¿—éªŒè¯æ­£åˆ™è¡¨è¾¾å¼")
            if "ruby" in pipeline_content.lower():
                guidance.append("â€¢ æ£€æµ‹åˆ° Ruby ä»£ç ï¼Œæ³¨æ„æ£€æŸ¥è¯­æ³•é”™è¯¯å’Œæ€§èƒ½å½±å“")
            if "mutate" in pipeline_content.lower():
                guidance.append("â€¢ æ£€æµ‹åˆ°å­—æ®µå˜æ¢ï¼ŒéªŒè¯å­—æ®µç±»å‹è½¬æ¢æ˜¯å¦æ­£ç¡®")
            if "date" in pipeline_content.lower():
                guidance.append("â€¢ æ£€æµ‹åˆ°æ—¶é—´è§£æï¼Œç¡®è®¤æ—¶é—´æ ¼å¼åŒ¹é…æ—¥å¿—æ ¼å¼")
        
        if test_logs:
            guidance.append("**æ—¥å¿—æ ·æœ¬åˆ†æ**:")
            guidance.append(f"â€¢ æä¾›äº† {len(test_logs)} æ¡æµ‹è¯•æ—¥å¿—")
            if any("<" in log and ">" in log for log in test_logs):
                guidance.append("â€¢ æ£€æµ‹åˆ° Syslog æ ¼å¼ï¼Œç¡®ä¿æ­£ç¡®è§£æä¼˜å…ˆçº§å­—æ®µ")
            if any('"' in log for log in test_logs):
                guidance.append("â€¢ æ£€æµ‹åˆ° JSON æˆ–å¼•å·ï¼Œæ³¨æ„è½¬ä¹‰å­—ç¬¦å¤„ç†")
        
        # 4. è‡ªåŠ¨åŒ–å·¥ä½œæµå»ºè®®
        guidance.append("\n## ğŸ”„ **è‡ªåŠ¨åŒ–å·¥ä½œæµ**")
        guidance.append("æ¨èä½¿ç”¨ `test_pipeline_complete_stream` è¿›è¡Œä¸€ç«™å¼æµ‹è¯•ï¼š")
        guidance.append("â€¢ è‡ªåŠ¨ä¸Šä¼ é…ç½® â†’ å‘é€æµ‹è¯•æ—¥å¿— â†’ è·å–ç»“æœ â†’ æ£€æŸ¥é”™è¯¯")
        guidance.append("â€¢ æ”¯æŒå®æ—¶æµå¼åé¦ˆï¼Œæ–¹ä¾¿ç›‘æ§æµ‹è¯•è¿›åº¦")
        guidance.append("â€¢ é€‚åˆæ‰¹é‡æµ‹è¯•å¤šæ¡æ—¥å¿—è®°å½•")
        
        # 5. å¸¸è§é—®é¢˜è§£å†³
        guidance.append("\n## âš ï¸ **å¸¸è§é—®é¢˜è§£å†³**")
        common_issues = [
            "**Grok è§£æå¤±è´¥**: æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼è¯­æ³•ï¼Œä½¿ç”¨åœ¨çº¿ Grok è°ƒè¯•å™¨",
            "**å­—æ®µç±»å‹é”™è¯¯**: æ£€æŸ¥ mutate æ’ä»¶çš„ç±»å‹è½¬æ¢é…ç½®",
            "**æ—¶é—´è§£æå¤±è´¥**: ç¡®è®¤ date æ’ä»¶çš„æ—¶é—´æ ¼å¼ä¸æ—¥å¿—ä¸€è‡´",
            "**æ€§èƒ½é—®é¢˜**: æ£€æŸ¥ Ruby ä»£ç å¤æ‚åº¦ï¼Œè€ƒè™‘ä½¿ç”¨åŸç”Ÿæ’ä»¶æ›¿ä»£",
            "**ç¼–ç é—®é¢˜**: æ³¨æ„ä¸­æ–‡ç­‰ç‰¹æ®Šå­—ç¬¦çš„ç¼–ç å¤„ç†"
        ]
        for issue in common_issues:
            guidance.append(f"â€¢ {issue}")
        
        guidance.append("\n---")
        guidance.append("ğŸ’¬ **æç¤º**: æ‚¨å¯ä»¥è¦æ±‚æˆ‘æŒ‰ç…§ä¸Šè¿°æ­¥éª¤è‡ªåŠ¨æ‰§è¡Œæµ‹è¯•ï¼Œæˆ‘ä¼šä½¿ç”¨ç›¸åº”çš„å·¥å…·æ¥å®Œæˆï¼")
        
        return "\n".join(guidance)
    
    def _generate_prompt_content(self, prompt_name: str, prompt_args: Dict[str, Any]) -> str:
        """ç”Ÿæˆå…·ä½“çš„æç¤ºå†…å®¹"""
        
        if prompt_name == "test_existing_config":
            config_type = prompt_args.get("config_type", "pipeline")
            return f"""è¯·å¸®æˆ‘æµ‹è¯•ç°æœ‰çš„ Logstash é…ç½®æ–‡ä»¶ã€‚

ğŸ“‹ **æµ‹è¯•ä»»åŠ¡**:
- é…ç½®ç±»å‹: {config_type}
- éªŒè¯é…ç½®è¯­æ³•æ˜¯å¦æ­£ç¡®
- æµ‹è¯•å®é™…æ—¥å¿—è§£ææ•ˆæœ
- æ£€æŸ¥å­—æ®µæå–å’Œç±»å‹è½¬æ¢

ğŸ”§ **æ¨èæµ‹è¯•æµç¨‹**:
1. **ä¸Šä¼ é…ç½®**: ä½¿ç”¨ `upload_pipeline` å·¥å…·ä¸Šä¼ æ‚¨çš„é…ç½®æ–‡ä»¶
2. **æ¸…ç©ºç°æœ‰è§£æè®°å½•**: ä½¿ç”¨ `clear_results` æ¸…ç†å†å²æ•°æ®
3. **å‘é€æµ‹è¯•æ—¥å¿—**: ä½¿ç”¨ `send_test_log` å‘é€æ ·æœ¬æ—¥å¿—è¿›è¡Œæµ‹è¯•
4. **æ£€æŸ¥è§£æç»“æœ**: ä½¿ç”¨ `get_parsed_results` æŸ¥çœ‹è§£æè¾“å‡º
5. **æŸ¥çœ‹é”™è¯¯æ—¥å¿—**: å¦‚æœ‰é—®é¢˜ä½¿ç”¨ `get_logstash_logs` æŸ¥çœ‹è¯¦ç»†é”™è¯¯
6. **å¥åº·æ£€æŸ¥**: ä½¿ç”¨ `health_check` ç¡®è®¤æœåŠ¡çŠ¶æ€

âš¡ **é‡è¦æç¤º**: 
- ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç† `if "xxx" == [@metadata][type]` æ¡ä»¶æ›¿æ¢
- æ‚¨æ— éœ€æ‹…å¿ƒæ¡ä»¶åŒ¹é…é—®é¢˜ï¼Œä¸“æ³¨æµ‹è¯•è§£æé€»è¾‘
- å¯ä»¥ä½¿ç”¨ `test_pipeline_complete_stream` è¿›è¡Œä¸€ç«™å¼æµå¼æµ‹è¯•

è¯·æä¾›æ‚¨çš„é…ç½®æ–‡ä»¶ï¼Œæˆ‘ä¼šå¸®æ‚¨å®Œæˆæµ‹è¯•ã€‚"""

        elif prompt_name == "test_log_matching":
            log_type = prompt_args.get("log_type", "custom")
            return f"""è¯·å¸®æˆ‘æµ‹è¯•æ—¥å¿—ä¸é…ç½®çš„åŒ¹é…æ•ˆæœã€‚

ğŸ“‹ **åŒ¹é…æµ‹è¯•ä»»åŠ¡**:
- æ—¥å¿—ç±»å‹: {log_type}
- éªŒè¯æ—¥å¿—æ ¼å¼ä¸é…ç½®çš„å…¼å®¹æ€§
- æ£€æŸ¥å­—æ®µæå–å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
- æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ—¥å¿—

ğŸ§ª **æµ‹è¯•æ­¥éª¤**:
1. **å‡†å¤‡æµ‹è¯•æ•°æ®**: æä¾›å¤šæ¡ä¸åŒæ ¼å¼çš„æ ·æœ¬æ—¥å¿—
2. **æ¸…ç©ºç°æœ‰è§£æè®°å½•**: ä½¿ç”¨ `clear_results` ç¡®ä¿æµ‹è¯•ç¯å¢ƒå¹²å‡€
3. **å‘é€æµ‹è¯•æ—¥å¿—**: ä½¿ç”¨ `send_test_log` é€æ¡æµ‹è¯•
4. **åˆ†æè§£æç»“æœ**: ä½¿ç”¨ `get_parsed_results` æ£€æŸ¥æ¯æ¡æ—¥å¿—çš„è§£ææ•ˆæœ
5. **å¯¹æ¯”æœŸæœ›è¾“å‡º**: éªŒè¯æå–çš„å­—æ®µæ˜¯å¦ç¬¦åˆé¢„æœŸ
6. **æ‰¹é‡æµ‹è¯•**: ä½¿ç”¨ `test_pipeline_complete_stream` æ‰¹é‡æµ‹è¯•å¤šæ¡æ—¥å¿—

ğŸ¯ **å…³æ³¨é‡ç‚¹**:
- å­—æ®µæå–æ˜¯å¦å®Œæ•´
- æ•°æ®ç±»å‹è½¬æ¢æ˜¯å¦æ­£ç¡®
- æ—¶é—´è§£ææ˜¯å¦å‡†ç¡®
- å¼‚å¸¸æ—¥å¿—çš„å¤„ç†æƒ…å†µ

âš¡ **è‡ªåŠ¨åŒ–ç‰¹æ€§**: 
- æ¡ä»¶åˆ¤æ–­è‡ªåŠ¨æ›¿æ¢ï¼Œæ— éœ€å…³å¿ƒ `[@metadata][type]` åŒ¹é…
- ä¸“æ³¨éªŒè¯è§£æé€»è¾‘çš„æ­£ç¡®æ€§

è¯·æä¾›æ‚¨çš„æ ·æœ¬æ—¥å¿—ï¼Œæˆ‘ä¼šå¸®æ‚¨æµ‹è¯•åŒ¹é…æ•ˆæœã€‚"""

        elif prompt_name == "debug_parsing_failure":
            error_type = prompt_args.get("error_type", "é€šç”¨è§£æé”™è¯¯")
            return f"""å¸®æˆ‘è°ƒè¯•æ—¥å¿—è§£æå¤±è´¥é—®é¢˜ã€‚

ğŸ“‹ **æ•…éšœè¯Šæ–­**:
- é”™è¯¯ç±»å‹: {error_type}
- åˆ†æè§£æå¤±è´¥çš„æ ¹æœ¬åŸå› 
- æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®
- éªŒè¯ä¿®å¤æ•ˆæœ

ğŸ” **è¯Šæ–­æµç¨‹**:
1. **è·å–é”™è¯¯ä¿¡æ¯**: ä½¿ç”¨ `get_logstash_logs` æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—
2. **æ¸…ç©ºå†å²æ•°æ®**: ä½¿ç”¨ `clear_results` æ¸…ç†æ—§çš„æµ‹è¯•ç»“æœ
3. **é‡ç°é—®é¢˜**: ä½¿ç”¨ `send_test_log` å‘é€å¤±è´¥çš„æ—¥å¿—æ ·æœ¬
4. **åˆ†æé”™è¯¯æ¨¡å¼**: æ£€æŸ¥ `get_parsed_results` ä¸­çš„é”™è¯¯æ ‡è®°
5. **éªŒè¯ä¿®å¤**: ä¿®æ”¹é…ç½®åé‡æ–°æµ‹è¯•

ğŸš¨ **å¸¸è§è§£æå¤±è´¥åŸå› **:
- **Grok æ¨¡å¼ä¸åŒ¹é…**: æ­£åˆ™è¡¨è¾¾å¼ä¸æ—¥å¿—æ ¼å¼ä¸ç¬¦
- **å­—æ®µåå†²çª**: å¤šä¸ªæ’ä»¶å®šä¹‰äº†ç›¸åŒå­—æ®µ
- **ç±»å‹è½¬æ¢é”™è¯¯**: æ•°æ®ç±»å‹è½¬æ¢å¤±è´¥
- **æ—¥æœŸè§£æå¤±è´¥**: æ—¶é—´æ ¼å¼ä¸åŒ¹é…
- **ç¼–ç é—®é¢˜**: ç‰¹æ®Šå­—ç¬¦æˆ–ç¼–ç å¯¼è‡´è§£æå¼‚å¸¸

ğŸ”§ **è°ƒè¯•æŠ€å·§**:
- ä½¿ç”¨ç®€åŒ–çš„ Grok æ¨¡å¼é€æ­¥è°ƒè¯•
- æ£€æŸ¥è½¬ä¹‰å­—ç¬¦çš„æ­£ç¡®æ€§
- éªŒè¯å­—æ®µå‘½åçš„ä¸€è‡´æ€§

è¯·æä¾›å¤±è´¥çš„æ—¥å¿—æ ·æœ¬å’Œé”™è¯¯ä¿¡æ¯ï¼Œæˆ‘ä¼šå¸®æ‚¨å®šä½å¹¶è§£å†³é—®é¢˜ã€‚"""

        elif prompt_name == "compare_before_after":
            modification_type = prompt_args.get("modification_type", "é…ç½®ä¼˜åŒ–")
            return f"""å¸®æˆ‘æ¯”è¾ƒé…ç½®ä¿®æ”¹å‰åçš„è§£ææ•ˆæœã€‚

ğŸ“‹ **å¯¹æ¯”æµ‹è¯•ä»»åŠ¡**:
- ä¿®æ”¹ç±»å‹: {modification_type}
- éªŒè¯ä¿®æ”¹æ˜¯å¦è¾¾åˆ°é¢„æœŸæ•ˆæœ
- ç¡®ä¿ä¸å¼•å…¥æ–°çš„è§£æé—®é¢˜
- è¯„ä¼°æ€§èƒ½å’Œå‡†ç¡®æ€§æ”¹è¿›

ğŸ”„ **å¯¹æ¯”æµ‹è¯•æµç¨‹**:
1. **ä¿å­˜åŸå§‹ç»“æœ**: 
   - ä½¿ç”¨å½“å‰é…ç½®æµ‹è¯•æ ·æœ¬æ—¥å¿—
   - ä¿å­˜ `get_parsed_results` çš„è¾“å‡ºä½œä¸ºåŸºå‡†
2. **åº”ç”¨æ–°é…ç½®**:
   - ä½¿ç”¨ `upload_pipeline` ä¸Šä¼ ä¿®æ”¹åçš„é…ç½®
   - ä½¿ç”¨ç›¸åŒæ—¥å¿—è¿›è¡Œæµ‹è¯•
3. **ç»“æœå¯¹æ¯”**:
   - å¯¹æ¯”ä¿®æ”¹å‰åçš„å­—æ®µæå–ç»“æœ
   - æ£€æŸ¥æ–°å¢ã€åˆ é™¤æˆ–ä¿®æ”¹çš„å­—æ®µ
   - éªŒè¯æ•°æ®å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
4. **æ€§èƒ½è¯„ä¼°**:
   - ä½¿ç”¨ `test_pipeline_complete_stream` æµ‹è¯•å¤„ç†é€Ÿåº¦
   - æ£€æŸ¥èµ„æºæ¶ˆè€—æƒ…å†µ

ğŸ“Š **å¯¹æ¯”ç»´åº¦**:
- âœ… **å­—æ®µå®Œæ•´æ€§**: å¿…è¦å­—æ®µæ˜¯å¦éƒ½è¢«æ­£ç¡®æå–
- âœ… **æ•°æ®å‡†ç¡®æ€§**: æå–çš„å€¼æ˜¯å¦æ­£ç¡®
- âœ… **ç±»å‹è½¬æ¢**: æ•°æ®ç±»å‹æ˜¯å¦ç¬¦åˆé¢„æœŸ
- âœ… **æ€§èƒ½è¡¨ç°**: å¤„ç†é€Ÿåº¦æ˜¯å¦æœ‰æ”¹å–„
- âœ… **é”™è¯¯ç‡**: è§£æå¤±è´¥çš„æ—¥å¿—æ˜¯å¦å‡å°‘

âš¡ **è‡ªåŠ¨åŒ–ä¼˜åŠ¿**: 
- ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ¡ä»¶åˆ¤æ–­ï¼Œç¡®ä¿æµ‹è¯•ä¸€è‡´æ€§
- å¯ä»¥å¿«é€Ÿåˆ‡æ¢å’Œå¯¹æ¯”ä¸åŒé…ç½®ç‰ˆæœ¬

è¯·æä¾›ä¿®æ”¹å‰åçš„é…ç½®å’Œæµ‹è¯•æ—¥å¿—ï¼Œæˆ‘ä¼šå¸®æ‚¨å®Œæˆè¯¦ç»†å¯¹æ¯”ã€‚"""

        elif prompt_name == "validate_field_extraction":
            expected_fields = prompt_args.get("expected_fields", "æ‰€æœ‰å­—æ®µ")
            return f"""å¸®æˆ‘éªŒè¯å­—æ®µæå–æ˜¯å¦æ­£ç¡®ã€‚

ğŸ“‹ **å­—æ®µéªŒè¯ä»»åŠ¡**:
- æœŸæœ›å­—æ®µ: {expected_fields}
- éªŒè¯å­—æ®µæå–çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
- æ£€æŸ¥æ•°æ®ç±»å‹è½¬æ¢æ˜¯å¦æ­£ç¡®
- ç¡®è®¤å­—æ®µæ˜ å°„å…³ç³»

âœ… **éªŒè¯æ£€æŸ¥é¡¹**:
1. **å­—æ®µå­˜åœ¨æ€§**: æ‰€æœ‰æœŸæœ›çš„å­—æ®µéƒ½è¢«æå–
2. **å­—æ®µå€¼å‡†ç¡®æ€§**: æå–çš„å€¼ä¸æ—¥å¿—å†…å®¹åŒ¹é…
3. **æ•°æ®ç±»å‹æ­£ç¡®æ€§**: æ•°å€¼ã€æ—¥æœŸã€å­—ç¬¦ä¸²ç±»å‹è½¬æ¢æ­£ç¡®
4. **å­—æ®µå‘½åè§„èŒƒ**: å­—æ®µåç¬¦åˆé¢„æœŸçš„å‘½åçº¦å®š
5. **ç‰¹æ®Šå­—æ®µå¤„ç†**: æ—¶é—´æˆ³ã€IPåœ°å€ç­‰ç‰¹æ®Šå­—æ®µæ ¼å¼æ­£ç¡®

ğŸ§ª **éªŒè¯æµç¨‹**:
1. **æ¸…ç©ºç°æœ‰è§£æè®°å½•**: ä½¿ç”¨ `clear_results` ç¡®ä¿æµ‹è¯•ç¯å¢ƒå¹²å‡€
2. **å‘é€æµ‹è¯•æ—¥å¿—**: ä½¿ç”¨ `send_test_log` å‘é€åŒ…å«æ‰€æœ‰å­—æ®µçš„æ—¥å¿—æ ·æœ¬
3. **è·å–è§£æç»“æœ**: ä½¿ç”¨ `get_parsed_results` æŸ¥çœ‹æå–çš„å­—æ®µ
4. **é€å­—æ®µæ£€æŸ¥**: éªŒè¯æ¯ä¸ªå­—æ®µçš„å­˜åœ¨æ€§å’Œå€¼çš„æ­£ç¡®æ€§
5. **ç±»å‹éªŒè¯**: æ£€æŸ¥æ•°å€¼å­—æ®µæ˜¯å¦ä¸ºæ•°å­—ç±»å‹ï¼Œæ—¥æœŸæ˜¯å¦æ­£ç¡®è§£æ
6. **è¾¹ç•Œæµ‹è¯•**: æµ‹è¯•ç¼ºå¤±å­—æ®µã€ç©ºå€¼ã€ç‰¹æ®Šå­—ç¬¦çš„å¤„ç†

ğŸ“ **éªŒè¯æŠ¥å‘Š**:
- âœ… æ­£ç¡®æå–çš„å­—æ®µåˆ—è¡¨
- âŒ ç¼ºå¤±æˆ–é”™è¯¯çš„å­—æ®µ
- ğŸ”„ éœ€è¦ä¿®æ”¹çš„é…ç½®å»ºè®®
- ğŸ“Š å­—æ®µæå–å®Œæ•´æ€§è¯„åˆ†

âš¡ **ç³»ç»Ÿç‰¹æ€§**: 
- è‡ªåŠ¨æ¡ä»¶åˆ¤æ–­æ›¿æ¢ï¼Œç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸€è‡´
- å¯ä»¥é‡å¤æµ‹è¯•å’ŒéªŒè¯ä¸åŒçš„æ—¥å¿—æ ·æœ¬

è¯·æä¾›æ‚¨çš„æœŸæœ›å­—æ®µåˆ—è¡¨å’Œæµ‹è¯•æ—¥å¿—ï¼Œæˆ‘ä¼šå¸®æ‚¨å®Œæˆè¯¦ç»†éªŒè¯ã€‚"""

        elif prompt_name == "batch_test_logs":
            test_scenario = prompt_args.get("test_scenario", "ç»¼åˆæµ‹è¯•")
            return f"""å¸®æˆ‘æ‰¹é‡æµ‹è¯•å¤šæ¡æ—¥å¿—è®°å½•ã€‚

ğŸ“‹ **æ‰¹é‡æµ‹è¯•ä»»åŠ¡**:
- æµ‹è¯•åœºæ™¯: {test_scenario}
- éªŒè¯é…ç½®å¯¹ä¸åŒæ—¥å¿—çš„å¤„ç†èƒ½åŠ›
- è¯†åˆ«æ½œåœ¨çš„è§£æé—®é¢˜å’Œè¾¹ç•Œæƒ…å†µ
- è¯„ä¼°æ•´ä½“è§£ææˆåŠŸç‡

ğŸ¯ **æµ‹è¯•åœºæ™¯ç±»å‹**:
- **æ­£å¸¸æ—¥å¿—**: æ ‡å‡†æ ¼å¼çš„å¸¸è§æ—¥å¿—
- **å¼‚å¸¸æ—¥å¿—**: æ ¼å¼ä¸å®Œæ•´æˆ–åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ—¥å¿—
- **è¾¹ç•Œæƒ…å†µ**: æé•¿å­—æ®µã€ç©ºå€¼ã€ç‰¹æ®Šç¼–ç ç­‰
- **æ··åˆæ ¼å¼**: ä¸åŒæ¥æºæˆ–æ—¶é—´æ®µçš„æ—¥å¿—æ··åˆ

ğŸš€ **æ‰¹é‡æµ‹è¯•æµç¨‹**:
1. **å‡†å¤‡æµ‹è¯•æ•°æ®é›†**: æ”¶é›†ä¸åŒç±»å‹çš„æ—¥å¿—æ ·æœ¬
2. **æ‰§è¡Œæ‰¹é‡æµ‹è¯•**: ä½¿ç”¨ `test_pipeline_complete_stream` å·¥å…·
   - æ”¯æŒå®æ—¶æµå¼åé¦ˆ
   - è‡ªåŠ¨å¤„ç†å¤šæ¡æ—¥å¿—
   - æä¾›è¯¦ç»†çš„è¿›åº¦æŠ¥å‘Š
3. **ç»“æœåˆ†æ**: 
   - ç»Ÿè®¡è§£ææˆåŠŸç‡
   - è¯†åˆ«è§£æå¤±è´¥çš„æ—¥å¿—æ¨¡å¼
   - åˆ†æå­—æ®µæå–çš„ä¸€è‡´æ€§
4. **é—®é¢˜è¯Šæ–­**: å¯¹å¤±è´¥çš„æ—¥å¿—ä½¿ç”¨ `get_logstash_logs` æŸ¥çœ‹é”™è¯¯

ğŸ“Š **æµ‹è¯•æŒ‡æ ‡**:
- ğŸ“ˆ **è§£ææˆåŠŸç‡**: æˆåŠŸè§£æçš„æ—¥å¿—ç™¾åˆ†æ¯”
- ğŸ¯ **å­—æ®µå®Œæ•´æ€§**: å…³é”®å­—æ®µçš„æå–ç‡
- âš¡ **å¤„ç†æ€§èƒ½**: æ¯ç§’å¤„ç†çš„æ—¥å¿—æ•°é‡
- ğŸš¨ **é”™è¯¯ç±»å‹åˆ†å¸ƒ**: ä¸åŒé”™è¯¯çš„é¢‘ç‡ç»Ÿè®¡

âœ¨ **æ‰¹é‡æµ‹è¯•ä¼˜åŠ¿**:
- æµå¼å¤„ç†ï¼Œå®æ—¶æŸ¥çœ‹æµ‹è¯•è¿›åº¦
- è‡ªåŠ¨æ±‡æ€»ç»Ÿè®¡ç»“æœ
- è¯†åˆ«é…ç½®çš„é²æ£’æ€§é—®é¢˜
- ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ¡ä»¶åˆ¤æ–­æ›¿æ¢

è¯·æä¾›æ‚¨çš„æ—¥å¿—æ•°æ®é›†ï¼Œæˆ‘ä¼šå¸®æ‚¨æ‰§è¡Œå…¨é¢çš„æ‰¹é‡æµ‹è¯•ã€‚"""

        else:
            return f"""æœªçŸ¥çš„æç¤ºç±»å‹: {prompt_name}

ğŸ”§ **å¯ç”¨çš„æµ‹è¯•æç¤º**:
- **test_existing_config**: æµ‹è¯•ç°æœ‰çš„ Logstash é…ç½®æ–‡ä»¶
- **test_log_matching**: æµ‹è¯•æ—¥å¿—ä¸é…ç½®çš„åŒ¹é…æ•ˆæœ  
- **debug_parsing_failure**: è°ƒè¯•æ—¥å¿—è§£æå¤±è´¥é—®é¢˜
- **compare_before_after**: æ¯”è¾ƒé…ç½®ä¿®æ”¹å‰åçš„è§£ææ•ˆæœ
- **validate_field_extraction**: éªŒè¯å­—æ®µæå–æ˜¯å¦æ­£ç¡®
- **batch_test_logs**: æ‰¹é‡æµ‹è¯•å¤šæ¡æ—¥å¿—è®°å½•

ğŸ’¡ **ä½¿ç”¨å»ºè®®**:
è¿™äº›æç¤ºä¸“é—¨é’ˆå¯¹å®é™…æµ‹è¯•åœºæ™¯è®¾è®¡ï¼Œå¸®åŠ©æ‚¨ï¼š
- å¿«é€Ÿæµ‹è¯•ç°æœ‰é…ç½®
- éªŒè¯æ—¥å¿—è§£ææ•ˆæœ
- è°ƒè¯•è§£æé—®é¢˜
- æ‰¹é‡æµ‹è¯•å’Œæ€§èƒ½è¯„ä¼°

è¯·é€‰æ‹©é€‚åˆæ‚¨å½“å‰éœ€æ±‚çš„æç¤ºç±»å‹ã€‚"""

# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
mcp_server = LogstashMCPServer()

# HTTP API è·¯ç”±å®šä¹‰
@app.route("/", methods=["GET"])
def index():
    """æœåŠ¡å™¨é¦–é¡µ"""
    return jsonify({
        "service": "Logstash SSE MCP Server",
        "version": "1.0.0",
        "description": "ä¸º AI æä¾› Logstash æµ‹è¯•å·¥å…·çš„ SSE æµå¼è°ƒç”¨æ¥å£",
        "start_time": mcp_server.start_time.isoformat(),
        "features": [
            "Server-Sent Events (SSE) æ”¯æŒ",
            "å®æ—¶è¿›åº¦åé¦ˆ",
            "æµå¼æµ‹è¯•ç»“æœ",
            "æ‰€æœ‰æ ‡å‡† MCP å·¥å…·"
        ],
        "available_tools": [
            "upload_pipeline",
            "test_pipeline_complete_stream", 
            "send_test_log",
            "get_parsed_results",
            "clear_results",
            "get_logstash_logs",
            "health_check"
        ],
        "docs": "/docs"
    })

@app.route("/docs", methods=["GET"])
def docs():
    """API æ–‡æ¡£"""
    return jsonify({
        "api_documentation": {
            "sse_endpoints": {
                "test_pipeline_complete_stream": {
                    "method": "GET",
                    "endpoint": "/sse/test_pipeline_complete",
                    "description": "SSE æµå¼å®Œæ•´æµ‹è¯•æµç¨‹",
                    "parameters": {
                        "pipeline_content": "string (required) - Pipeline é…ç½®å†…å®¹",
                        "test_logs": "array (required) - æµ‹è¯•æ—¥å¿—åˆ—è¡¨ï¼ˆJSON ç¼–ç ï¼‰",
                        "is_json": "boolean (optional) - æ˜¯å¦ä¸º JSON æ ¼å¼ï¼Œé»˜è®¤ false",
                        "wait_time": "integer (optional) - ç­‰å¾…çƒ­é‡è½½æ—¶é—´ï¼Œé»˜è®¤ 3 ç§’"
                    },
                    "response_format": "text/event-stream",
                    "event_types": [
                        "start - å¼€å§‹æµç¨‹",
                        "progress - è¿›åº¦æ›´æ–°", 
                        "success - æ­¥éª¤æˆåŠŸ",
                        "error - é”™è¯¯ä¿¡æ¯",
                        "warning - è­¦å‘Šä¿¡æ¯",
                        "complete - æµç¨‹å®Œæˆ"
                    ]
                }
            },
            "standard_endpoints": {
                "upload_pipeline": {
                    "method": "POST",
                    "endpoint": "/tools/upload_pipeline",
                    "description": "ä¸Šä¼ å®Œæ•´çš„ Logstash pipeline é…ç½®"
                },
                "send_test_log": {
                    "method": "POST",
                    "endpoint": "/tools/send_test_log", 
                    "description": "å‘é€æµ‹è¯•æ—¥å¿—"
                },
                "get_parsed_results": {
                    "method": "GET",
                    "endpoint": "/tools/get_parsed_results",
                    "description": "è·å–è§£æç»“æœ"
                },
                "clear_results": {
                    "method": "POST",
                    "endpoint": "/tools/clear_results",
                    "description": "æ¸…ç©ºè§£æç»“æœ"
                },
                "get_logstash_logs": {
                    "method": "GET", 
                    "endpoint": "/tools/get_logstash_logs",
                    "description": "è·å– Logstash æ—¥å¿—"
                },
                "health_check": {
                    "method": "GET",
                    "endpoint": "/tools/health_check",
                    "description": "å¥åº·æ£€æŸ¥"
                }
            }
        }
    })

# SSE æµå¼æ¥å£
@app.route("/sse/test_pipeline_complete", methods=["GET"])
def sse_test_pipeline_complete():
    """SSE æµå¼å®Œæ•´æµ‹è¯•æµç¨‹"""
    try:
        pipeline_content = request.args.get("pipeline_content", "")
        test_logs_json = request.args.get("test_logs", "[]")
        is_json = request.args.get("is_json", "false").lower() == "true"
        wait_time = int(request.args.get("wait_time", "3"))
        
        if not pipeline_content:
            return jsonify({"error": "ç¼ºå°‘ pipeline_content å‚æ•°"}), 400
        
        try:
            test_logs = json.loads(test_logs_json)
        except json.JSONDecodeError:
            return jsonify({"error": "test_logs å‚æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON æ•°ç»„"}), 400
        
        if not test_logs:
            return jsonify({"error": "test_logs ä¸èƒ½ä¸ºç©º"}), 400
        
        def generate():
            yield from mcp_server.test_pipeline_complete_stream(
                pipeline_content, test_logs, is_json, wait_time
            )
        
        return Response(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'Cache-Control'
            }
        )
    
    except Exception as e:
        return jsonify({"error": str(e), "traceback": traceback.format_exc()}), 500

# MCP åè®®æ”¯æŒ
@app.route("/mcp", methods=["POST"])
def mcp_handler():
    """å¤„ç† MCP (Model Context Protocol) è¯·æ±‚"""
    try:
        if not request.is_json:
            return jsonify({"error": "MCP è¯·æ±‚å¿…é¡»æ˜¯ JSON æ ¼å¼"}), 400
        
        data = request.get_json()
        
        # æ£€æŸ¥ JSON-RPC æ ¼å¼
        if not isinstance(data, dict) or "method" not in data:
            return jsonify({"error": "æ— æ•ˆçš„ JSON-RPC è¯·æ±‚"}), 400
        
        method = data.get("method")
        params = data.get("params", {})
        request_id = data.get("id")
        
        # å¤„ç†ä¸åŒçš„ MCP æ–¹æ³•
        if method == "initialize":
            # MCP æ ‡å‡†åˆå§‹åŒ–åè®®
            client_info = params.get("clientInfo", {})
            protocol_version = params.get("protocolVersion", "2024-11-05")
            capabilities = params.get("capabilities", {})
            
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "tools": {
                            "listChanged": True
                        },
                        "logging": {},
                        "prompts": {
                            "listChanged": True
                        },
                        "resources": {},
                        "sampling": {}
                    },
                    "serverInfo": {
                        "name": "Logstash MCP Server",
                        "version": "1.0.0",
                        "description": "Logstash è§„åˆ™æµ‹è¯•å’Œè°ƒè¯•å·¥å…· MCP æœåŠ¡å™¨"
                    }
                }
            })
        
        elif method == "notifications/initialized":
            # MCP åˆå§‹åŒ–å®Œæˆé€šçŸ¥ - è¿”å›ç©ºçš„æˆåŠŸå“åº”
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {}
            })
        
        elif method == "list_prompts" or method == "prompts/list":
            # è¿”å›å¯ç”¨æç¤ºåˆ—è¡¨
            prompts = [
                {
                    "name": "test_existing_config",
                    "description": "æµ‹è¯•ç°æœ‰çš„ Logstash é…ç½®æ–‡ä»¶",
                    "arguments": [
                        {
                            "name": "config_type",
                            "description": "é…ç½®ç±»å‹ (filter/pipeline/å®Œæ•´é…ç½®)",
                            "required": False
                        }
                    ]
                },
                {
                    "name": "test_log_matching",
                    "description": "æµ‹è¯•æ—¥å¿—ä¸é…ç½®çš„åŒ¹é…æ•ˆæœ",
                    "arguments": [
                        {
                            "name": "log_type",
                            "description": "æ—¥å¿—ç±»å‹ (nginx/apache/syslog/json/custom)",
                            "required": False
                        }
                    ]
                },
                {
                    "name": "debug_parsing_failure",
                    "description": "è°ƒè¯•æ—¥å¿—è§£æå¤±è´¥é—®é¢˜",
                    "arguments": [
                        {
                            "name": "error_type",
                            "description": "é”™è¯¯ç±»å‹ (grok_failure/json_parse_error/date_parse_error)",
                            "required": False
                        }
                    ]
                },
                {
                    "name": "compare_before_after",
                    "description": "æ¯”è¾ƒé…ç½®ä¿®æ”¹å‰åçš„è§£ææ•ˆæœ",
                    "arguments": [
                        {
                            "name": "modification_type",
                            "description": "ä¿®æ”¹ç±»å‹ (grok_pattern/field_mapping/date_format)",
                            "required": False
                        }
                    ]
                },
                {
                    "name": "validate_field_extraction",
                    "description": "éªŒè¯å­—æ®µæå–æ˜¯å¦æ­£ç¡®",
                    "arguments": [
                        {
                            "name": "expected_fields",
                            "description": "æœŸæœ›æå–çš„å­—æ®µåˆ—è¡¨",
                            "required": False
                        }
                    ]
                },
                {
                    "name": "batch_test_logs",
                    "description": "æ‰¹é‡æµ‹è¯•å¤šæ¡æ—¥å¿—è®°å½•",
                    "arguments": [
                        {
                            "name": "test_scenario",
                            "description": "æµ‹è¯•åœºæ™¯ (æ­£å¸¸æ—¥å¿—/å¼‚å¸¸æ—¥å¿—/è¾¹ç•Œæƒ…å†µ)",
                            "required": False
                        }
                    ]
                }
            ]
            
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "prompts": prompts
                }
            })
        
        elif method == "get_prompt" or method == "prompts/get":
            prompt_name = params.get("name")
            prompt_args = params.get("arguments", {})
            
            # ç”Ÿæˆå…·ä½“çš„æç¤ºå†…å®¹
            prompt_content = mcp_server._generate_prompt_content(prompt_name, prompt_args)
            
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "description": f"Logstash é…ç½®æç¤º: {prompt_name}",
                    "messages": [
                        {
                            "role": "user",
                            "content": {
                                "type": "text",
                                "text": prompt_content
                            }
                        }
                    ]
                }
            })
        
        elif method == "list_tools" or method == "tools/list":
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "result": {
                    "tools": [
                        {
                            "name": "upload_pipeline",
                            "description": "ä¸Šä¼ å®Œæ•´çš„ Logstash Pipeline é…ç½®æ–‡ä»¶ï¼Œè‡ªåŠ¨æå– filter å—å¹¶åº”ç”¨åˆ°æµ‹è¯•ç¯å¢ƒã€‚é‡è¦ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨å°†ä»»ä½• if \"xxx\" == [@metadata][type] æ¡ä»¶æ›¿æ¢ä¸º if \"test\" == [@metadata][type]ï¼Œæ‚¨æ— éœ€æ‹…å¿ƒæ¡ä»¶åŒ¹é…é—®é¢˜",
                            "inputSchema": {
                                "type": "object",
                                "properties": {
                                    "pipeline_content": {
                                        "type": "string",
                                        "description": "å®Œæ•´çš„ Pipeline é…ç½®å†…å®¹"
                                    },
                                    "use_file_upload": {
                                        "type": "boolean",
                                        "description": "æ˜¯å¦ä¸ºæ–‡ä»¶ä¸Šä¼ æ–¹å¼",
                                        "default": True
                                    }
                                },
                                "required": ["pipeline_content"]
                            }
                        },
                        {
                            "name": "send_test_log",
                            "description": "å‘é€æµ‹è¯•æ—¥å¿—åˆ° Logstash è¿›è¡Œè§£æ",
                            "inputSchema": {
                                "type": "object",
                                "properties": {
                                    "log_content": {
                                        "type": "string",
                                        "description": "è¦æµ‹è¯•çš„æ—¥å¿—å†…å®¹"
                                    },
                                    "is_json": {
                                        "type": "boolean",
                                        "description": "æ—¥å¿—æ˜¯å¦ä¸º JSON æ ¼å¼",
                                        "default": False
                                    }
                                },
                                "required": ["log_content"]
                            }
                        },
                        {
                            "name": "get_parsed_results",
                            "description": "è·å–æœ€æ–°çš„è§£æç»“æœ",
                            "inputSchema": {
                                "type": "object",
                                "properties": {},
                                "additionalProperties": False
                            }
                        },
                        {
                            "name": "clear_results",
                            "description": "æ¸…ç©ºå†å²è§£æç»“æœ",
                            "inputSchema": {
                                "type": "object",
                                "properties": {},
                                "additionalProperties": False
                            }
                        },
                        {
                            "name": "get_logstash_logs",
                            "description": "è·å– Logstash è¿è¡Œæ—¥å¿—",
                            "inputSchema": {
                                "type": "object",
                                "properties": {},
                                "additionalProperties": False
                            }
                        },
                        {
                            "name": "test_pipeline_complete_stream",
                            "description": "æ‰§è¡Œå®Œæ•´çš„ Pipeline æµ‹è¯•æµç¨‹ï¼ŒåŒ…æ‹¬ä¸Šä¼ é…ç½®ã€å‘é€æµ‹è¯•æ—¥å¿—ã€è·å–ç»“æœã€‚æ”¯æŒ SSE æµå¼åé¦ˆ",
                            "inputSchema": {
                                "type": "object",
                                "properties": {
                                    "pipeline_content": {
                                        "type": "string",
                                        "description": "Pipeline é…ç½®å†…å®¹"
                                    },
                                    "test_logs": {
                                        "type": "array",
                                        "items": {
                                            "type": "string"
                                        },
                                        "description": "æµ‹è¯•æ—¥å¿—åˆ—è¡¨"
                                    },
                                    "is_json": {
                                        "type": "boolean",
                                        "description": "æ—¥å¿—æ˜¯å¦ä¸º JSON æ ¼å¼",
                                        "default": False
                                    },
                                    "wait_time": {
                                        "type": "integer",
                                        "description": "ç­‰å¾…çƒ­é‡è½½æ—¶é—´ï¼ˆç§’ï¼‰",
                                        "default": 3
                                    }
                                },
                                "required": ["pipeline_content", "test_logs"]
                            }
                        },
                        {
                            "name": "get_test_guidance",
                            "description": "è·å–æ™ºèƒ½æµ‹è¯•æŒ‡å¯¼ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨åˆ†æå¹¶æä¾›æµ‹è¯•å»ºè®®å’Œæ­¥éª¤é¡ºåº",
                            "inputSchema": {
                                "type": "object",
                                "properties": {
                                    "user_request": {
                                        "type": "string",
                                        "description": "ç”¨æˆ·çš„æµ‹è¯•è¯·æ±‚æˆ–é—®é¢˜æè¿°"
                                    },
                                    "pipeline_content": {
                                        "type": "string",
                                        "description": "å¯é€‰ï¼šPipeline é…ç½®å†…å®¹ï¼Œç”¨äºåˆ†æå’Œå»ºè®®"
                                    },
                                    "test_logs": {
                                        "type": "array",
                                        "items": {"type": "string"},
                                        "description": "å¯é€‰ï¼šæµ‹è¯•æ—¥å¿—æ ·æœ¬ï¼Œç”¨äºåˆ†ææ ¼å¼å’Œå†…å®¹"
                                    }
                                },
                                "required": ["user_request"]
                            }
                        },
                        {
                            "name": "health_check",
                            "description": "æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€",
                            "inputSchema": {
                                "type": "object",
                                "properties": {},
                                "additionalProperties": False
                            }
                        }
                    ]
                }
            })
        
        elif method == "call_tool" or method == "tools/call":
            tool_name = params.get("name")
            tool_args = params.get("arguments", {})
            
            if tool_name == "upload_pipeline":
                result = mcp_server.upload_pipeline(
                    tool_args.get("pipeline_content", ""),
                    tool_args.get("use_file_upload", True)
                )
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"Pipeline ä¸Šä¼ ç»“æœï¼š\n{json.dumps(result, ensure_ascii=False, indent=2)}"
                            }
                        ],
                        "isError": not result.get("success", False)
                    }
                })
            
            elif tool_name == "send_test_log":
                result = mcp_server.send_test_log(
                    tool_args.get("log_content", ""),
                    tool_args.get("is_json", False)
                )
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"æµ‹è¯•æ—¥å¿—å‘é€ç»“æœï¼š\n{json.dumps(result, ensure_ascii=False, indent=2)}"
                            }
                        ],
                        "isError": not result.get("success", False)
                    }
                })
            
            elif tool_name == "get_parsed_results":
                result = mcp_server.get_parsed_results()
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"è§£æç»“æœï¼š\n{json.dumps(result, ensure_ascii=False, indent=2)}"
                            }
                        ]
                    }
                })
            
            elif tool_name == "clear_results":
                result = mcp_server.clear_results()
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"æ¸…ç©ºç»“æœï¼š{result.get('message', 'æ“ä½œå®Œæˆ')}"
                            }
                        ]
                    }
                })
            
            elif tool_name == "get_logstash_logs":
                result = mcp_server.get_logstash_logs()
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"Logstash æ—¥å¿—ï¼š\n{result.get('logs', 'æ— æ—¥å¿—')[-2000:]}"  # é™åˆ¶é•¿åº¦
                            }
                        ]
                    }
                })
            
            elif tool_name == "test_pipeline_complete_stream":
                # å¯¹äºæµå¼å·¥å…·ï¼Œè¿”å› SSE ç«¯ç‚¹ä¿¡æ¯
                pipeline_content = tool_args.get("pipeline_content", "")
                test_logs = tool_args.get("test_logs", [])
                is_json = tool_args.get("is_json", False)
                wait_time = tool_args.get("wait_time", 3)
                
                # æ„å»º SSE URL
                sse_url = f"{request.url_root}sse/test_pipeline_complete"
                params_dict = {
                    "pipeline_content": pipeline_content,
                    "test_logs": json.dumps(test_logs),
                    "is_json": str(is_json).lower(),
                    "wait_time": str(wait_time)
                }
                
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"SSE æµå¼æµ‹è¯•å·²å¯åŠ¨ã€‚\n\nè¯·ä½¿ç”¨ä»¥ä¸‹ä¿¡æ¯è¿æ¥ SSE æµï¼š\n\nURL: {sse_url}\nå‚æ•°: {json.dumps(params_dict, ensure_ascii=False, indent=2)}\n\næˆ–ç›´æ¥è®¿é—®æµ‹è¯•é¡µé¢: {request.url_root}test"
                            }
                        ]
                    }
                })
            
            elif tool_name == "get_test_guidance":
                guidance = mcp_server.get_test_guidance(
                    tool_args.get("user_request", ""),
                    tool_args.get("pipeline_content", ""),
                    tool_args.get("test_logs", [])
                )
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": guidance
                            }
                        ]
                    }
                })
            
            elif tool_name == "health_check":
                result = mcp_server.health_check()
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "content": [
                            {
                                "type": "text",
                                "text": f"å¥åº·æ£€æŸ¥ç»“æœï¼š\nçŠ¶æ€: {'å¥åº·' if result.get('healthy') else 'å¼‚å¸¸'}\nè¯¦æƒ…: {json.dumps(result.get('details', {}), ensure_ascii=False, indent=2)}"
                            }
                        ]
                    }
                })
            
            else:
                return jsonify({
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {
                        "code": -32601,
                        "message": f"æœªçŸ¥çš„å·¥å…·: {tool_name}"
                    }
                }), 400
        
        else:
            return jsonify({
                "jsonrpc": "2.0",
                "id": request_id,
                "error": {
                    "code": -32601,
                    "message": f"æœªçŸ¥çš„æ–¹æ³•: {method}"
                }
            }), 400
    
    except Exception as e:
        return jsonify({
            "jsonrpc": "2.0",
            "id": data.get("id") if isinstance(data, dict) else None,
            "error": {
                "code": -32603,
                "message": f"å†…éƒ¨é”™è¯¯: {str(e)}",
                "data": traceback.format_exc()
            }
        }), 500

# æ ‡å‡† REST API æ¥å£ï¼ˆä¸ network_mcp_server.py å…¼å®¹ï¼‰
@app.route("/tools/upload_pipeline", methods=["POST"])
def api_upload_pipeline():
    """ä¸Šä¼  Pipeline é…ç½®"""
    try:
        pipeline_content = ""
        use_file_upload = True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶ä¸Šä¼ 
        if 'file' in request.files:
            # æ–‡ä»¶ä¸Šä¼ æ–¹å¼
            file = request.files['file']
            if file.filename:
                pipeline_content = file.read().decode('utf-8')
                use_file_upload = True
        elif 'pipeline' in request.form:
            # è¡¨å•æ•°æ®æ–¹å¼
            pipeline_content = request.form.get('pipeline', '')
            use_file_upload = False
        elif request.is_json:
            # JSON æ•°æ®æ–¹å¼
            data = request.get_json()
            pipeline_content = data.get("pipeline_content", "")
            use_file_upload = data.get("use_file_upload", True)
        else:
            return jsonify({"success": False, "error": "æœªæä¾› pipeline å†…å®¹"}), 400
        
        if not pipeline_content:
            return jsonify({"success": False, "error": "ç¼ºå°‘ pipeline_content å‚æ•°"}), 400
        
        result = mcp_server.upload_pipeline(pipeline_content, use_file_upload)
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/tools/send_test_log", methods=["POST"])
def api_send_test_log():
    """å‘é€æµ‹è¯•æ—¥å¿—"""
    try:
        data = request.get_json()
        log_content = data.get("log_content", "")
        is_json = data.get("is_json", False)
        
        if not log_content:
            return jsonify({"success": False, "error": "ç¼ºå°‘ log_content å‚æ•°"}), 400
        
        result = mcp_server.send_test_log(log_content, is_json)
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/tools/get_parsed_results", methods=["GET"])
def api_get_parsed_results():
    """è·å–è§£æç»“æœ"""
    try:
        count = request.args.get("count", -1, type=int)
        result = mcp_server.get_parsed_results(count)
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/tools/clear_results", methods=["POST"])
def api_clear_results():
    """æ¸…ç©ºè§£æç»“æœ"""
    try:
        result = mcp_server.clear_results()
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/tools/get_logstash_logs", methods=["GET"])
def api_get_logstash_logs():
    """è·å– Logstash æ—¥å¿—"""
    try:
        filter_errors = request.args.get("filter_errors", "false").lower() == "true"
        result = mcp_server.get_logstash_logs(filter_errors)
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

@app.route("/tools/health_check", methods=["GET"])
def api_health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        result = mcp_server.health_check()
        return jsonify(result)
    
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "traceback": traceback.format_exc()}), 500

# SSE æµ‹è¯•é¡µé¢
@app.route("/test", methods=["GET"])
def test_page():
    """SSE æµ‹è¯•é¡µé¢"""
    return """
<!DOCTYPE html>
<html>
<head>
    <title>SSE MCP Server æµ‹è¯•</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .container { max-width: 800px; }
        textarea { width: 100%; height: 200px; font-family: monospace; }
        button { padding: 10px 20px; margin: 5px; }
        .log { 
            background: #f5f5f5; 
            border: 1px solid #ddd; 
            padding: 10px; 
            height: 400px; 
            overflow-y: scroll; 
            font-family: monospace; 
            white-space: pre-wrap;
        }
        .event { margin: 5px 0; padding: 5px; border-left: 3px solid #ccc; }
        .start { border-left-color: #007bff; }
        .progress { border-left-color: #ffc107; }
        .success { border-left-color: #28a745; }
        .error { border-left-color: #dc3545; }
        .warning { border-left-color: #fd7e14; }
        .complete { border-left-color: #6f42c1; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸŒŠ SSE MCP Server æµ‹è¯•</h1>
        
        <h3>Pipeline é…ç½®:</h3>
        <textarea id="pipelineContent">
input {
  http { port => 15515 }
}
filter {
  if "apache" == [@metadata][type] {
    grok { match => { "message" => "%{COMBINEDAPACHELOG}" } }
    mutate { rename => { "clientip" => "src_ip" } }
  }
}
output {
  file { path => "/data/out/events.ndjson" }
}
        </textarea>
        
        <h3>æµ‹è¯•æ—¥å¿—:</h3>
        <textarea id="testLogs">127.0.0.1 - - [25/Dec/2023:10:00:00 +0000] "GET /index.html HTTP/1.1" 200 2326
192.168.1.100 - - [25/Dec/2023:10:00:01 +0000] "POST /api/login HTTP/1.1" 401 128</textarea>
        
        <div>
            <button onclick="startSSETest()">ğŸš€ å¼€å§‹ SSE æµå¼æµ‹è¯•</button>
            <button onclick="clearLog()">ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—</button>
        </div>
        
        <h3>å®æ—¶æ—¥å¿—:</h3>
        <div id="logOutput" class="log"></div>
    </div>
    
    <script>
        let eventSource = null;
        
        function startSSETest() {
            const pipelineContent = document.getElementById('pipelineContent').value;
            const testLogsText = document.getElementById('testLogs').value;
            const testLogs = testLogsText.split('\\n').filter(line => line.trim());
            
            if (!pipelineContent.trim() || testLogs.length === 0) {
                alert('è¯·è¾“å…¥ Pipeline é…ç½®å’Œæµ‹è¯•æ—¥å¿—');
                return;
            }
            
            // å…³é—­ä¹‹å‰çš„è¿æ¥
            if (eventSource) {
                eventSource.close();
            }
            
            clearLog();
            addLog('ğŸ”Œ æ­£åœ¨è¿æ¥ SSE æµ...', 'progress');
            
            // æ„å»º URL
            const params = new URLSearchParams({
                pipeline_content: pipelineContent,
                test_logs: JSON.stringify(testLogs),
                is_json: 'false',
                wait_time: '3'
            });
            
            const url = `/sse/test_pipeline_complete?${params.toString()}`;
            
            // åˆ›å»º SSE è¿æ¥
            eventSource = new EventSource(url);
            
            eventSource.onopen = function(event) {
                addLog('âœ… SSE è¿æ¥å·²å»ºç«‹', 'success');
            };
            
            eventSource.onmessage = function(event) {
                try {
                    const data = JSON.parse(event.data);
                    const timestamp = new Date(data.timestamp).toLocaleTimeString();
                    const message = `[${timestamp}] ${data.type.toUpperCase()}: ${data.data.message || JSON.stringify(data.data)}`;
                    addLog(message, data.type);
                    
                    if (data.type === 'complete' || data.type === 'error') {
                        addLog('ğŸ æµç¨‹ç»“æŸï¼Œè¿æ¥å°†å…³é—­', 'complete');
                        eventSource.close();
                        eventSource = null;
                    }
                } catch (e) {
                    addLog(`è§£æäº‹ä»¶å¤±è´¥: ${event.data}`, 'error');
                }
            };
            
            eventSource.onerror = function(event) {
                addLog('âŒ SSE è¿æ¥é”™è¯¯', 'error');
                eventSource.close();
                eventSource = null;
            };
        }
        
        function addLog(message, type = 'info') {
            const logOutput = document.getElementById('logOutput');
            const eventDiv = document.createElement('div');
            eventDiv.className = `event ${type}`;
            eventDiv.textContent = message;
            logOutput.appendChild(eventDiv);
            logOutput.scrollTop = logOutput.scrollHeight;
        }
        
        function clearLog() {
            document.getElementById('logOutput').innerHTML = '';
        }
        
        // é¡µé¢å…³é—­æ—¶æ¸…ç†è¿æ¥
        window.addEventListener('beforeunload', function() {
            if (eventSource) {
                eventSource.close();
            }
        });
    </script>
</body>
</html>
    """

if __name__ == "__main__":
    print("ğŸŒŠ å¯åŠ¨ Logstash MCP Server (SSE æ”¯æŒ)...")
    print(f"ğŸ“¡ æœåŠ¡åœ°å€: http://0.0.0.0:19001")
    print(f"ğŸ“š API æ–‡æ¡£: http://0.0.0.0:19001/docs")
    print(f"ğŸ§ª æµ‹è¯•é¡µé¢: http://0.0.0.0:19001/test")
    print(f"ğŸŒŠ SSE æ¥å£: http://0.0.0.0:19001/sse/test_pipeline_complete")
    print(f"ğŸ”— Logstash æœåŠ¡: {LOGSTASH_SERVICE_URL}")
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å¼€å‘æ¨¡å¼
    is_development = os.getenv("FLASK_ENV") == "development"
    app.run(host="0.0.0.0", port=19001, debug=is_development, use_reloader=is_development)
